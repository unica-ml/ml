{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNo1+BHoEb4ad9zVURm2q+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unica-ml/ml/blob/master/notebooks/Transformers_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformers-LLMs Laboratory\n",
        "\n",
        "\n",
        "In this laboratory, we'll go through some of the main concepts of Transformer architecture [1] and Large Language Models.\n",
        "\n",
        "In the first part, we will implement a simplified version of the attention mechanism from scratch!\n",
        "The code is partially inspired by the [Build a Large Language Model (From Scratch)](https://github.com/rasbt/LLMs-from-scratch) [2] repository (strongly suggested if you want to learn more).\n",
        "\n",
        "\n",
        "## Tokenization\n",
        "\n",
        "First of all, we need a tokenizer to process the input text and get tokens and their IDs. We'll use a pre-trained one, in this case, the GPT2 [3] tokenizer, which can be loaded from [Hugging Face](https://huggingface.co/).\n",
        "\n",
        "Hugging Face is the main reference for all that concerns transformers (not only applied to text): they provide all the development resources (e.g., transformers and tokenizers libraries) and host datasets and pre-trained models."
      ],
      "metadata": {
        "id": "SWYJrAoNAB3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec\n",
        "!pip install bertviz"
      ],
      "metadata": {
        "id": "NA6MdOGGQox3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ],
      "metadata": {
        "id": "WeigRqxHB0Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look to the tokenizer vocabulary!"
      ],
      "metadata": {
        "id": "ttTmXt9pCx9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Vocab size:\", tokenizer.vocab_size)\n",
        "print()\n",
        "for i, (token, id) in enumerate(tokenizer.vocab.items()):\n",
        "  if i == 10:\n",
        "    break\n",
        "  print(token, id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlgPwhAfCvCq",
        "outputId": "207f3409-9505-4702-bf8a-95a8465b022f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 50257\n",
            "\n",
            "Ġrests 24013\n",
            "Ġsensing 34244\n",
            "UD 8322\n",
            "Ġml 25962\n",
            "Ġrevenge 15827\n",
            "Ġsafety 3747\n",
            "Ġswift 14622\n",
            "Ġtownship 42823\n",
            "ĠPrism 35417\n",
            "ĠPiper 33503\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizers expose different methods to obtain tokens and IDs from text (and vice versa). Now we create a sentence and try some of them:\n",
        "- `tokenize` returns a list of tokens\n",
        "- `encode` returns a list of token IDs\n",
        "- `__call__` returns a dictionary that contains different data. For instance, the token IDs (key `input_ids`) and the attention mask (key `attention_mask`), which tells the model if to consider tokens (value 1) or not (value 0, typically used for padding tokens)."
      ],
      "metadata": {
        "id": "b49gYKdxE0sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"A sequence of words.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "ids = tokenizer.encode(sentence)\n",
        "print(\"IDs:\", ids)\n",
        "\n",
        "encoding = tokenizer(sentence)\n",
        "print(\"Encoding:\", encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWd7CrMFFBBU",
        "outputId": "813a9a54-2023-4c6a-a49a-f273ea28d799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['A', 'Ġsequence', 'Ġof', 'Ġwords', '.']\n",
            "IDs: [32, 8379, 286, 2456, 13]\n",
            "Encoding: {'input_ids': [32, 8379, 286, 2456, 13], 'attention_mask': [1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding\n",
        "\n",
        "Once we have token IDs, we can compute embeddings. For now, let's simulate this step, as it would require training one or more embedding layers.\n",
        "We then create a random embedding representation $X$ with $d=4$ for each token."
      ],
      "metadata": {
        "id": "cVCan1HkH92d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "X = torch.rand(5, 4)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVOKWiElIHl-",
        "outputId": "912e5250-f7c7-40e2-945f-7b4c322591d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3570, 0.0826, 0.7419, 0.4303],\n",
            "        [0.9318, 0.0557, 0.6334, 0.0181],\n",
            "        [0.1714, 0.6355, 0.2957, 0.9169],\n",
            "        [0.8550, 0.2291, 0.6086, 0.4313],\n",
            "        [0.0544, 0.7056, 0.1190, 0.5368]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-Attention\n",
        "\n",
        "We start with a simplified example, excluding for now the trainable parameters $W_q, W_k, W_v$ of the attention layer, so that $Q=K=V=X$.\n",
        "\n",
        "\n",
        "Recalling the attention layer equation:\n",
        "\n",
        "$Attention(Q,K,V)=softmax(\\frac{QK^T}{\\sqrt{d_k}})V$,\n",
        "\n",
        "where $\\frac{QK^T}{\\sqrt{d_k}}$ are the attention scores,\n",
        "and $softmax(\\frac{QK^T}{\\sqrt{d_k}})$ the attention weights.\n",
        "\n",
        "The final resulting output is called context vector.\n",
        "\n",
        "\n",
        "Let's first compute the self-attention score of the second token $x_1$ with respect to the third token $x_2$."
      ],
      "metadata": {
        "id": "sBZ4i3-rG3_T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = X[1, :]\n",
        "k = X[2, :]\n",
        "\n",
        "attention_score_1_vs_2 = q.dot(k)\n",
        "print(attention_score_1_vs_2.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytm8uF8-II8g",
        "outputId": "7f737c58-2fc6-41fd-df63-f28f232f5fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39895498752593994"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we multiply the matrices $Q$ and $K$, we will obtain the attention scores for every token pair."
      ],
      "metadata": {
        "id": "TF6ILZQUIM8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Q = X\n",
        "K = X\n",
        "\n",
        "attention_scores = Q @ K.T\n",
        "print(attention_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7H0GsFVINES",
        "outputId": "a172b255-fb66-4fe7-f43d-e6447055c27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8699, 0.8150, 0.7276, 0.9613, 0.3970],\n",
              "        [0.8150, 1.2729, 0.3990, 1.2028, 0.1751],\n",
              "        [0.7276, 0.3990, 1.3614, 0.8675, 0.9852],\n",
              "        [0.9613, 1.2028, 0.8675, 1.3400, 0.5121],\n",
              "        [0.3970, 0.1751, 0.9852, 0.5121, 0.8032]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following step consists of scaling and normalizing the attention scores to obtain the attention weights (such that the attention weights for each token sum to 1).\n",
        "\n",
        "The attention weights matrix always has shape ($n\\_tokens$, $n\\_tokens$)."
      ],
      "metadata": {
        "id": "v6xDmjiMIOnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = torch.softmax(attention_scores / X.shape[1]**0.5, dim=1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0dE464PIOs5",
        "outputId": "23c92801-992e-4ac0-fd9b-19a70c1a9254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2109, 0.2052, 0.1965, 0.2208, 0.1665],\n",
              "        [0.1996, 0.2510, 0.1621, 0.2423, 0.1450],\n",
              "        [0.1841, 0.1562, 0.2528, 0.1975, 0.2094],\n",
              "        [0.1965, 0.2217, 0.1875, 0.2374, 0.1570],\n",
              "        [0.1811, 0.1621, 0.2430, 0.1918, 0.2219]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we obtain the context vectors as a weighted sum of the Values matrix with respect to the attention weights."
      ],
      "metadata": {
        "id": "ibGLKTLBIQVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "V = X\n",
        "\n",
        "context_vectors = attention_weights @ V\n",
        "print(context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpEo5Ve8IQa5",
        "outputId": "4e3d460b-3c25-45c0-dc7e-8c5196a84680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4981, 0.3218, 0.4988, 0.4592],\n",
              "        [0.5480, 0.2913, 0.5198, 0.4214],\n",
              "        [0.4349, 0.3776, 0.4554, 0.5114],\n",
              "        [0.5204, 0.3128, 0.5048, 0.4471],\n",
              "        [0.4335, 0.3790, 0.4521, 0.5056]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context vectors can be viewed as higher-level embedding representations, which enclose information about the relationships between input tokens.\n",
        "\n",
        "However, the models need some trainable parameters in order to learn how to produce those richer representations!\n",
        "\n",
        "We thus (randomly) create the key, query, and values weights $W_q, W_k, W_v$, and compute the respective matrices as $Q=XW_q$, $K=XW_k$, and $V=XW_v$.\n",
        "\n",
        "Note that while the first dimension of the weight matrices must correspond to the input dimensionality, the second dimension can assume any value and represents the dimension of each produced context vector."
      ],
      "metadata": {
        "id": "GU_0cUzmISXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_q = torch.rand(size=(4, 3))\n",
        "W_k = torch.rand(size=(4, 3))\n",
        "W_v = torch.rand(size=(4, 3))\n",
        "\n",
        "Q = X @ W_q\n",
        "K = X @ W_k\n",
        "V = X @ W_v\n",
        "\n",
        "attention_scores = Q @ K.T\n",
        "attention_weights = torch.softmax(attention_scores / X.shape[1]**0.5, dim=1)\n",
        "context_vectors = attention_weights @ V\n",
        "print(context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9i0tWTxISde",
        "outputId": "1befad71-2de3-4690-d96b-1e61ab2bc77c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.3110, 1.0721, 0.6139],\n",
            "        [1.3169, 1.0757, 0.6191],\n",
            "        [1.3151, 1.0737, 0.6178],\n",
            "        [1.3204, 1.0759, 0.6231],\n",
            "        [1.3106, 1.0741, 0.6121]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just built the main block of the Transformers architecture!\n",
        "\n",
        "Actually, that was just one attention _head_... in practice, each attention layer has multiple parallel heads, and their outputs are concatenated.\n",
        "\n",
        "Also, recall that in decoders, _masked_ attention is used, so that the model cannot rely on _future_ tokens in the input sequence.\n",
        "\n",
        "The masking must be performed **before** applying the softmax function. Otherwise, the resulting attention weights won't sum to 1. To do so, we can replace the attention scores that we want to mask with $-\\infty$ values: when applying the softmax function, they will become $0$."
      ],
      "metadata": {
        "id": "i0djaVw9sbNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_scores = Q @ K.T\n",
        "mask = torch.triu(torch.ones(attention_scores.shape), diagonal=1)\n",
        "attention_scores = attention_scores.masked_fill(mask.bool(), -torch.inf)\n",
        "attention_weights = torch.softmax(attention_scores / X.shape[1]**0.5, dim=1)\n",
        "print(attention_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x_sUIsVt7Vw",
        "outputId": "92b6d38e-eb06-46db-af42-4902acd55616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.4583, 0.5417, 0.0000, 0.0000, 0.0000],\n",
            "        [0.2502, 0.2771, 0.4727, 0.0000, 0.0000],\n",
            "        [0.1567, 0.1846, 0.3428, 0.3158, 0.0000],\n",
            "        [0.1560, 0.1733, 0.2473, 0.2379, 0.1855]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading a pretrained model\n",
        "\n",
        "We now load a pre-trained decoder-only model for text generation, i.e., GPT2 [3]. Implementation and weights are publicly available and can be retrieved from Hugging Face."
      ],
      "metadata": {
        "id": "YiBShcwiIT44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoModelForCausalLM\n",
        "\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hlf6ZkZ5IT-x",
        "outputId": "6618cba3-7cc8-4551-d62b-0ea76f04ebba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D(nf=2304, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=768)\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D(nf=3072, nx=768)\n",
            "          (c_proj): Conv1D(nf=768, nx=3072)\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model takes as input a sequence of token IDs (the attention mask is not required) and returns (inside a dictionary-like data structure), for each input token, a distribution over the next predicted token."
      ],
      "metadata": {
        "id": "DtQkFxOtIWJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Machine Learning algorithms are\"\n",
        "input_dict = tokenizer(sentence, return_tensors=\"pt\")\n",
        "output = model(input_ids=input_dict[\"input_ids\"], output_attentions=True)\n",
        "print(output.keys())\n",
        "print(output[\"logits\"].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LGpcLm_IWO7",
        "outputId": "c90c469c-2a68-42f2-fd88-0bd84a6ccfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to eager attention. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['logits', 'past_key_values', 'attentions'])\n",
            "torch.Size([1, 4, 50257])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's inspect and visualize the attention weights!"
      ],
      "metadata": {
        "id": "n5f1UHr8sAhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bertviz import head_view, model_view\n",
        "\n",
        "\n",
        "print(len(output.attentions))  # number of attention layers\n",
        "print(output.attentions[0].shape)  # (batch_size, num_heads, sequence_length, sequence_length)\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_dict[\"input_ids\"][0])\n",
        "head_view(output[-1], tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "yYmWVQQYTT0L",
        "outputId": "a26500b2-2e06-4cbd-8761-172979a11de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "torch.Size([1, 12, 4, 4])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      \n",
              "        <div id=\"bertviz-6f380e475bd44dc99a57a16401bd9f53\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
              "            <span style=\"user-select:none\">\n",
              "                Layer: <select id=\"layer\"></select>\n",
              "                \n",
              "            </span>\n",
              "            <div id='vis'></div>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " *\n",
              " *  Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 12/19/18  Jesse Vig   Assorted cleanup. Changed orientation of attention matrices.\n",
              " * 12/29/20  Jesse Vig   Significant refactor.\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
              " * 05/03/21  Jesse Vig   Adjust height of visualization dynamically\n",
              " * 07/25/21  Jesse Vig   Support layer filtering\n",
              " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
              " **/\n",
              "\n",
              "require.config({\n",
              "  paths: {\n",
              "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
              "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "  }\n",
              "});\n",
              "\n",
              "requirejs(['jquery', 'd3'], function ($, d3) {\n",
              "\n",
              "    const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0], [0.8369596600532532, 0.16304033994674683, 0.0, 0.0], [0.5454381704330444, 0.3083677887916565, 0.1461939960718155, 0.0], [0.495052307844162, 0.2794095277786255, 0.14270007610321045, 0.0828380137681961]], [[1.0, 0.0, 0.0, 0.0], [0.000313624826958403, 0.9996863603591919, 0.0, 0.0], [0.00028791805380024016, 0.00802256353199482, 0.9916894435882568, 0.0], [0.0005425689159892499, 0.0032627112232148647, 0.0006531100952997804, 0.9955416321754456]], [[1.0, 0.0, 0.0, 0.0], [0.8448778390884399, 0.15512219071388245, 0.0, 0.0], [0.5251489877700806, 0.275814414024353, 0.19903653860092163, 0.0], [0.36849015951156616, 0.1658337414264679, 0.17271070182323456, 0.2929653823375702]], [[1.0, 0.0, 0.0, 0.0], [0.24503926932811737, 0.7549607157707214, 0.0, 0.0], [0.07685161381959915, 0.007359172683209181, 0.9157891869544983, 0.0], [0.05555616691708565, 0.036348260939121246, 0.06720822304487228, 0.8408873677253723]], [[1.0, 0.0, 0.0, 0.0], [0.9365429878234863, 0.06345698982477188, 0.0, 0.0], [0.3796883821487427, 0.11549505591392517, 0.5048165321350098, 0.0], [0.25266125798225403, 0.11302568763494492, 0.4062349796295166, 0.22807802259922028]], [[1.0, 0.0, 0.0, 0.0], [0.08450809866189957, 0.9154918789863586, 0.0, 0.0], [0.035101741552352905, 0.00024448824115097523, 0.9646537899971008, 0.0], [0.047608859837055206, 0.0005061915726400912, 0.0009468193165957928, 0.9509381055831909]], [[1.0, 0.0, 0.0, 0.0], [0.9110549688339233, 0.08894503861665726, 0.0, 0.0], [0.48893216252326965, 0.17591167986392975, 0.3351562023162842, 0.0], [0.38058727979660034, 0.22310711443424225, 0.3622194528579712, 0.03408609330654144]], [[1.0, 0.0, 0.0, 0.0], [0.9978750944137573, 0.0021248599514365196, 0.0, 0.0], [0.3374008238315582, 0.5339188575744629, 0.12868033349514008, 0.0], [0.17422336339950562, 0.228385791182518, 0.40501347184181213, 0.19237743318080902]], [[1.0, 0.0, 0.0, 0.0], [0.9152600169181824, 0.08473993092775345, 0.0, 0.0], [0.5479149222373962, 0.3631327748298645, 0.08895225822925568, 0.0], [0.16942870616912842, 0.08551950752735138, 0.0642383024096489, 0.6808134913444519]], [[1.0, 0.0, 0.0, 0.0], [0.9147995114326477, 0.0852004662156105, 0.0, 0.0], [0.7048966288566589, 0.21635966002941132, 0.07874368876218796, 0.0], [0.4142463505268097, 0.14826752245426178, 0.17459677159786224, 0.2628893554210663]], [[1.0, 0.0, 0.0, 0.0], [0.6071661114692688, 0.3928338289260864, 0.0, 0.0], [0.46326571702957153, 0.18070173263549805, 0.35603249073028564, 0.0], [0.29799604415893555, 0.1267867088317871, 0.11243902146816254, 0.4627783000469208]], [[1.0, 0.0, 0.0, 0.0], [0.6133790612220764, 0.38662096858024597, 0.0, 0.0], [0.33036354184150696, 0.20231738686561584, 0.4673191010951996, 0.0], [0.3790343701839447, 0.14877310395240784, 0.2053280770778656, 0.26686444878578186]]], [[[1.0, 0.0, 0.0, 0.0], [0.9704445600509644, 0.029555508866906166, 0.0, 0.0], [0.6386247277259827, 0.22806428372859955, 0.1333109438419342, 0.0], [0.37808969616889954, 0.1540047824382782, 0.23913003504276276, 0.22877545654773712]], [[1.0, 0.0, 0.0, 0.0], [0.9330123066902161, 0.06698770821094513, 0.0, 0.0], [0.7352873682975769, 0.13050943613052368, 0.1342032104730606, 0.0], [0.5596781373023987, 0.1153513714671135, 0.1315806657075882, 0.19338980317115784]], [[1.0, 0.0, 0.0, 0.0], [0.974357008934021, 0.025642987340688705, 0.0, 0.0], [0.6994037628173828, 0.059934210032224655, 0.24066203832626343, 0.0], [0.493990033864975, 0.04794042557477951, 0.17723573744297028, 0.2808338701725006]], [[1.0, 0.0, 0.0, 0.0], [0.6114571690559387, 0.3885428309440613, 0.0, 0.0], [0.6385886669158936, 0.17295996844768524, 0.1884513795375824, 0.0], [0.5487473011016846, 0.13837896287441254, 0.15583735704421997, 0.15703636407852173]], [[1.0, 0.0, 0.0, 0.0], [0.9063447117805481, 0.09365527331829071, 0.0, 0.0], [0.7631184458732605, 0.10433613508939743, 0.13254539668560028, 0.0], [0.6749664545059204, 0.10557929426431656, 0.12621375918388367, 0.09324046224355698]], [[1.0, 0.0, 0.0, 0.0], [0.8225984573364258, 0.1774015873670578, 0.0, 0.0], [0.494573712348938, 0.2700279951095581, 0.2353982776403427, 0.0], [0.4025273323059082, 0.08602583408355713, 0.05536993592977524, 0.45607680082321167]], [[1.0, 0.0, 0.0, 0.0], [0.9537613987922668, 0.04623857140541077, 0.0, 0.0], [0.6869997382164001, 0.17357608675956726, 0.13942420482635498, 0.0], [0.8128571510314941, 0.07806374132633209, 0.058629702776670456, 0.05044940486550331]], [[1.0, 0.0, 0.0, 0.0], [0.9553384184837341, 0.04466155916452408, 0.0, 0.0], [0.7505393624305725, 0.17406539618968964, 0.07539532333612442, 0.0], [0.6242748498916626, 0.10723694413900375, 0.1399562656879425, 0.12853190302848816]], [[1.0, 0.0, 0.0, 0.0], [0.8932788372039795, 0.10672123730182648, 0.0, 0.0], [0.7336891889572144, 0.10167518258094788, 0.16463567316532135, 0.0], [0.5917772650718689, 0.10893679410219193, 0.12896184623241425, 0.17032407224178314]], [[1.0, 0.0, 0.0, 0.0], [0.9785101413726807, 0.02148984931409359, 0.0, 0.0], [0.8446694016456604, 0.07469841092824936, 0.08063214272260666, 0.0], [0.7354145646095276, 0.05895343795418739, 0.0681559219956398, 0.13747596740722656]], [[1.0, 0.0, 0.0, 0.0], [0.00028119742637500167, 0.9997187256813049, 0.0, 0.0], [0.0008738978649489582, 0.5217098593711853, 0.4774162769317627, 0.0], [0.0009776718216016889, 0.3428777754306793, 0.33847033977508545, 0.3176741898059845]], [[1.0, 0.0, 0.0, 0.0], [0.29874947667121887, 0.7012505531311035, 0.0, 0.0], [0.1370234489440918, 0.029669342562556267, 0.8333072066307068, 0.0], [0.09141987562179565, 0.005299035459756851, 0.0023187785409390926, 0.9009623527526855]]], [[[1.0, 0.0, 0.0, 0.0], [0.979323148727417, 0.020676879212260246, 0.0, 0.0], [0.8653432726860046, 0.0966615304350853, 0.03799512982368469, 0.0], [0.7161295413970947, 0.10998967289924622, 0.08727509528398514, 0.08660577982664108]], [[1.0, 0.0, 0.0, 0.0], [0.9533320665359497, 0.046667978167533875, 0.0, 0.0], [0.6956794261932373, 0.18802674114704132, 0.11629381775856018, 0.0], [0.8644037842750549, 0.021114042028784752, 0.018893064931035042, 0.09558915346860886]], [[1.0, 0.0, 0.0, 0.0], [0.9927532076835632, 0.007246746215969324, 0.0, 0.0], [0.3032039403915405, 0.64506596326828, 0.05173014849424362, 0.0], [0.32077324390411377, 0.1233762577176094, 0.3800252377986908, 0.17582522332668304]], [[1.0, 0.0, 0.0, 0.0], [0.9649205207824707, 0.035079460591077805, 0.0, 0.0], [0.6518253684043884, 0.2649356424808502, 0.08323896676301956, 0.0], [0.5497181415557861, 0.33758386969566345, 0.05332303047180176, 0.05937488004565239]], [[1.0, 0.0, 0.0, 0.0], [0.9978498220443726, 0.0021502331364899874, 0.0, 0.0], [0.916073203086853, 0.035401538014411926, 0.04852518439292908, 0.0], [0.7424127459526062, 0.05997372046113014, 0.029520198702812195, 0.16809333860874176]], [[1.0, 0.0, 0.0, 0.0], [0.982830286026001, 0.017169665545225143, 0.0, 0.0], [0.7756311297416687, 0.16884750127792358, 0.055521368980407715, 0.0], [0.4917299449443817, 0.09442475438117981, 0.15344028174877167, 0.260405033826828]], [[1.0, 0.0, 0.0, 0.0], [0.957459032535553, 0.04254094883799553, 0.0, 0.0], [0.8769592642784119, 0.06309546530246735, 0.059945233166217804, 0.0], [0.8289990425109863, 0.06033581495285034, 0.04139074683189392, 0.0692744255065918]], [[1.0, 0.0, 0.0, 0.0], [0.7742899060249329, 0.22571012377738953, 0.0, 0.0], [0.44242358207702637, 0.15451042354106903, 0.403065949678421, 0.0], [0.3363172113895416, 0.08960270881652832, 0.26217737793922424, 0.3119026720523834]], [[1.0, 0.0, 0.0, 0.0], [0.975498378276825, 0.024501606822013855, 0.0, 0.0], [0.6640846133232117, 0.24570739269256592, 0.09020791947841644, 0.0], [0.4707483649253845, 0.13731087744235992, 0.1213899701833725, 0.27055081725120544]], [[1.0, 0.0, 0.0, 0.0], [0.9771293997764587, 0.022870643064379692, 0.0, 0.0], [0.5135151743888855, 0.3658927083015442, 0.12059206515550613, 0.0], [0.3294655680656433, 0.15208598971366882, 0.4792048931121826, 0.03924347087740898]], [[1.0, 0.0, 0.0, 0.0], [0.834203839302063, 0.1657961755990982, 0.0, 0.0], [0.5445191860198975, 0.15962029993534088, 0.29586052894592285, 0.0], [0.47055649757385254, 0.1510101705789566, 0.2120228111743927, 0.16641049087047577]], [[1.0, 0.0, 0.0, 0.0], [0.947394073009491, 0.05260597914457321, 0.0, 0.0], [0.8473399877548218, 0.05213896930217743, 0.10052114725112915, 0.0], [0.7784276008605957, 0.051031529903411865, 0.08721314370632172, 0.08332774043083191]]], [[[1.0, 0.0, 0.0, 0.0], [0.9902021288871765, 0.009797906503081322, 0.0, 0.0], [0.974983274936676, 0.0026431484147906303, 0.022373542189598083, 0.0], [0.980229377746582, 0.0002615370904095471, 0.0005459703970700502, 0.018963150680065155]], [[1.0, 0.0, 0.0, 0.0], [0.9891428351402283, 0.010857130400836468, 0.0, 0.0], [0.975196361541748, 0.01235035341233015, 0.012453315779566765, 0.0], [0.9287400841712952, 0.007586255203932524, 0.001763215521350503, 0.061910390853881836]], [[1.0, 0.0, 0.0, 0.0], [0.893498420715332, 0.10650157183408737, 0.0, 0.0], [0.6191083192825317, 0.2279088944196701, 0.15298277139663696, 0.0], [0.31921836733818054, 0.3756026029586792, 0.17115254700183868, 0.13402636349201202]], [[1.0, 0.0, 0.0, 0.0], [0.8705539107322693, 0.1294460892677307, 0.0, 0.0], [0.7996733784675598, 0.14678318798542023, 0.053543440997600555, 0.0], [0.8236583471298218, 0.0546727254986763, 0.06270219385623932, 0.0589667446911335]], [[1.0, 0.0, 0.0, 0.0], [0.998528003692627, 0.0014719455502927303, 0.0, 0.0], [0.9905322790145874, 0.006602975074201822, 0.002864750102162361, 0.0], [0.9665279388427734, 0.003725797636434436, 0.010092132724821568, 0.01965402252972126]], [[1.0, 0.0, 0.0, 0.0], [0.9768734574317932, 0.023126551881432533, 0.0, 0.0], [0.8967821598052979, 0.0488673597574234, 0.05435044318437576, 0.0], [0.9002225995063782, 0.02542898990213871, 0.041070606559515, 0.03327779099345207]], [[1.0, 0.0, 0.0, 0.0], [0.9477744698524475, 0.052225545048713684, 0.0, 0.0], [0.4087452292442322, 0.4693022668361664, 0.12195252627134323, 0.0], [0.259976863861084, 0.4564320147037506, 0.19631369411945343, 0.08727742731571198]], [[1.0, 0.0, 0.0, 0.0], [0.8056485652923584, 0.19435137510299683, 0.0, 0.0], [0.21869415044784546, 0.6502187252044678, 0.13108715415000916, 0.0], [0.16758395731449127, 0.19799543917179108, 0.5688384175300598, 0.06558214873075485]], [[1.0, 0.0, 0.0, 0.0], [0.9566323757171631, 0.04336763918399811, 0.0, 0.0], [0.7401798963546753, 0.15399986505508423, 0.10582025349140167, 0.0], [0.4607292413711548, 0.16108983755111694, 0.040174126625061035, 0.33800676465034485]], [[1.0, 0.0, 0.0, 0.0], [0.994489312171936, 0.005510695278644562, 0.0, 0.0], [0.9145376086235046, 0.05818839743733406, 0.027273952960968018, 0.0], [0.7961251139640808, 0.022507833316922188, 0.007412086706608534, 0.1739550083875656]], [[1.0, 0.0, 0.0, 0.0], [0.9707838296890259, 0.029216134920716286, 0.0, 0.0], [0.7331598997116089, 0.08832243084907532, 0.17851771414279938, 0.0], [0.8049229383468628, 0.02779119275510311, 0.08374433219432831, 0.08354155719280243]], [[1.0, 0.0, 0.0, 0.0], [0.9712401628494263, 0.028759876266121864, 0.0, 0.0], [0.845210075378418, 0.04490312933921814, 0.10988675057888031, 0.0], [0.7398038506507874, 0.037047337740659714, 0.0495198629796505, 0.17362898588180542]]], [[[1.0, 0.0, 0.0, 0.0], [0.9693757891654968, 0.030624130740761757, 0.0, 0.0], [0.9188656210899353, 0.03805970773100853, 0.043074700981378555, 0.0], [0.9319638013839722, 0.0013976383488625288, 0.005987958051264286, 0.06065056100487709]], [[1.0, 0.0, 0.0, 0.0], [0.9800292253494263, 0.01997075229883194, 0.0, 0.0], [0.9718928337097168, 0.003747849026694894, 0.024359365925192833, 0.0], [0.9573526382446289, 0.0025618774816393852, 0.008242323994636536, 0.03184313699603081]], [[1.0, 0.0, 0.0, 0.0], [0.9867386817932129, 0.013261334039270878, 0.0, 0.0], [0.9557056427001953, 0.019744232296943665, 0.024550138041377068, 0.0], [0.9501595497131348, 0.008854535408318043, 0.01007052045315504, 0.030915414914488792]], [[1.0, 0.0, 0.0, 0.0], [0.8265204429626465, 0.1734795719385147, 0.0, 0.0], [0.6355267763137817, 0.25672414898872375, 0.10774916410446167, 0.0], [0.18620295822620392, 0.040084898471832275, 0.7422723770141602, 0.031439781188964844]], [[1.0, 0.0, 0.0, 0.0], [0.7905768156051636, 0.20942318439483643, 0.0, 0.0], [0.519731342792511, 0.18113018572330475, 0.29913851618766785, 0.0], [0.7743175625801086, 0.05341408774256706, 0.12167904525995255, 0.05058928206562996]], [[1.0, 0.0, 0.0, 0.0], [0.9885457158088684, 0.011454344727098942, 0.0, 0.0], [0.8765727877616882, 0.03792751580476761, 0.08549966663122177, 0.0], [0.903056263923645, 0.023861736059188843, 0.04364444315433502, 0.029437562450766563]], [[1.0, 0.0, 0.0, 0.0], [0.9562316536903381, 0.04376841336488724, 0.0, 0.0], [0.8558523058891296, 0.11495095491409302, 0.029196711257100105, 0.0], [0.6696529984474182, 0.16483807563781738, 0.1096738949418068, 0.05583502724766731]], [[1.0, 0.0, 0.0, 0.0], [0.9639875292778015, 0.0360124446451664, 0.0, 0.0], [0.5806638598442078, 0.03554213047027588, 0.38379406929016113, 0.0], [0.4580995440483093, 0.012987391091883183, 0.1599356234073639, 0.36897745728492737]], [[1.0, 0.0, 0.0, 0.0], [0.961618959903717, 0.038381047546863556, 0.0, 0.0], [0.9179849624633789, 0.030934102833271027, 0.051080986857414246, 0.0], [0.8626840114593506, 0.012464135885238647, 0.0717041939496994, 0.053147658705711365]], [[1.0, 0.0, 0.0, 0.0], [0.9893536567687988, 0.010646392591297626, 0.0, 0.0], [0.9517208933830261, 0.00560116209089756, 0.04267798736691475, 0.0], [0.9782204031944275, 0.0009760136599652469, 0.005679030902683735, 0.015124460682272911]], [[1.0, 0.0, 0.0, 0.0], [0.9727651476860046, 0.027234844863414764, 0.0, 0.0], [0.866966724395752, 0.07700687646865845, 0.056026410311460495, 0.0], [0.9648429751396179, 0.014742870815098286, 0.00617409311234951, 0.01424003392457962]], [[1.0, 0.0, 0.0, 0.0], [0.9999716281890869, 2.8336497052805498e-05, 0.0, 0.0], [1.1262841326242778e-06, 0.9998111128807068, 0.0001878697657957673, 0.0], [8.906245518858213e-09, 1.1331393579894211e-05, 0.999985933303833, 2.7121138828078983e-06]]], [[[1.0, 0.0, 0.0, 0.0], [0.9836140871047974, 0.016385985538363457, 0.0, 0.0], [0.9765778183937073, 0.009898822754621506, 0.013523346744477749, 0.0], [0.9769649505615234, 0.002553685335442424, 0.001368800294585526, 0.01911252923309803]], [[1.0, 0.0, 0.0, 0.0], [0.9999068975448608, 9.312301699537784e-05, 0.0, 0.0], [0.9983245730400085, 4.8447847802890465e-05, 0.001627017860300839, 0.0], [0.9986074566841125, 5.2555124057107605e-06, 1.3999418115417939e-05, 0.0013733254745602608]], [[1.0, 0.0, 0.0, 0.0], [0.879912793636322, 0.12008718401193619, 0.0, 0.0], [0.6022446155548096, 0.27633413672447205, 0.12142125517129898, 0.0], [0.6311676502227783, 0.08535166829824448, 0.24289457499980927, 0.04058617725968361]], [[1.0, 0.0, 0.0, 0.0], [0.9340515732765198, 0.06594836711883545, 0.0, 0.0], [0.5871796607971191, 0.25288164615631104, 0.15993866324424744, 0.0], [0.6978021264076233, 0.09078722447156906, 0.08866176754236221, 0.12274889647960663]], [[1.0, 0.0, 0.0, 0.0], [0.975918173789978, 0.024081889539957047, 0.0, 0.0], [0.8064600825309753, 0.07989509403705597, 0.11364487558603287, 0.0], [0.898098886013031, 0.013392063789069653, 0.04240615665912628, 0.04610288143157959]], [[1.0, 0.0, 0.0, 0.0], [0.9912323355674744, 0.00876766350120306, 0.0, 0.0], [0.9758439064025879, 0.01937630958855152, 0.0047797453589737415, 0.0], [0.9574930667877197, 0.008500847965478897, 0.006429125554859638, 0.027576982975006104]], [[1.0, 0.0, 0.0, 0.0], [0.9392426609992981, 0.0607573501765728, 0.0, 0.0], [0.6449490785598755, 0.2738036811351776, 0.08124731481075287, 0.0], [0.8555845022201538, 0.005867495201528072, 0.08781339973211288, 0.05073460191488266]], [[1.0, 0.0, 0.0, 0.0], [0.9653253555297852, 0.03467467427253723, 0.0, 0.0], [0.9449016451835632, 0.023804590106010437, 0.03129380941390991, 0.0], [0.9815472364425659, 0.0012909608194604516, 0.011074836365878582, 0.00608696136623621]], [[1.0, 0.0, 0.0, 0.0], [0.9680588841438293, 0.031941067427396774, 0.0, 0.0], [0.8569985032081604, 0.06653749197721481, 0.0764639750123024, 0.0], [0.9378696084022522, 0.008969446644186974, 0.009564449079334736, 0.04359638690948486]], [[1.0, 0.0, 0.0, 0.0], [0.975807249546051, 0.02419278584420681, 0.0, 0.0], [0.9480755925178528, 0.04677429422736168, 0.005150042474269867, 0.0], [0.8044395446777344, 0.06546380370855331, 0.07469691336154938, 0.055399760603904724]], [[1.0, 0.0, 0.0, 0.0], [0.6921703815460205, 0.3078295886516571, 0.0, 0.0], [0.6430989503860474, 0.3076874613761902, 0.04921359568834305, 0.0], [0.4546832740306854, 0.183853879570961, 0.21879146993160248, 0.1426713764667511]], [[1.0, 0.0, 0.0, 0.0], [0.9623194336891174, 0.037680484354496, 0.0, 0.0], [0.8048304915428162, 0.09014122933149338, 0.10502833127975464, 0.0], [0.5883017778396606, 0.05813616141676903, 0.07127902656793594, 0.2822830080986023]]], [[[1.0, 0.0, 0.0, 0.0], [0.8478448390960693, 0.15215519070625305, 0.0, 0.0], [0.7306845784187317, 0.121076300740242, 0.1482391208410263, 0.0], [0.6748157143592834, 0.04602762684226036, 0.19763080775737762, 0.08152579516172409]], [[1.0, 0.0, 0.0, 0.0], [0.9823725819587708, 0.017627395689487457, 0.0, 0.0], [0.9468225240707397, 0.006157270632684231, 0.04702017828822136, 0.0], [0.8949708342552185, 0.02156319096684456, 0.07169516384601593, 0.011770790442824364]], [[1.0, 0.0, 0.0, 0.0], [0.9561967849731445, 0.04380320757627487, 0.0, 0.0], [0.8608885407447815, 0.08694235980510712, 0.052169013768434525, 0.0], [0.8861517906188965, 0.04828586056828499, 0.02329666167497635, 0.04226572439074516]], [[1.0, 0.0, 0.0, 0.0], [0.981881320476532, 0.018118679523468018, 0.0, 0.0], [0.9134630560874939, 0.03209998086094856, 0.05443696677684784, 0.0], [0.875910222530365, 0.024367760866880417, 0.057334378361701965, 0.04238774999976158]], [[1.0, 0.0, 0.0, 0.0], [0.9381165504455566, 0.06188347563147545, 0.0, 0.0], [0.970572292804718, 0.020803941413760185, 0.008623836562037468, 0.0], [0.8397429585456848, 0.040844790637493134, 0.024267971515655518, 0.09514429420232773]], [[1.0, 0.0, 0.0, 0.0], [0.9257916212081909, 0.07420840114355087, 0.0, 0.0], [0.8414416909217834, 0.07572581619024277, 0.08283250033855438, 0.0], [0.873722493648529, 0.039385709911584854, 0.056421391665935516, 0.03047034703195095]], [[1.0, 0.0, 0.0, 0.0], [0.9303593039512634, 0.06964066624641418, 0.0, 0.0], [0.9047715067863464, 0.0456433929502964, 0.049585066735744476, 0.0], [0.920358419418335, 0.014210919849574566, 0.013970093801617622, 0.051460664719343185]], [[1.0, 0.0, 0.0, 0.0], [0.8821121454238892, 0.11788780242204666, 0.0, 0.0], [0.8118640184402466, 0.12519629299640656, 0.06293972581624985, 0.0], [0.6577447056770325, 0.12387697398662567, 0.17867420613765717, 0.03970417007803917]], [[1.0, 0.0, 0.0, 0.0], [0.705574631690979, 0.2944253981113434, 0.0, 0.0], [0.40366578102111816, 0.4589470624923706, 0.13738717138767242, 0.0], [0.5951082706451416, 0.08372033387422562, 0.2782452404499054, 0.04292619973421097]], [[1.0, 0.0, 0.0, 0.0], [0.9989274144172668, 0.0010725656757131219, 0.0, 0.0], [0.9955834746360779, 0.0005400340305641294, 0.003876502625644207, 0.0], [0.9955409169197083, 0.0015136642614379525, 0.0010158899240195751, 0.0019296339014545083]], [[1.0, 0.0, 0.0, 0.0], [0.9712175726890564, 0.02878241427242756, 0.0, 0.0], [0.9646689891815186, 0.008357902057468891, 0.02697315439581871, 0.0], [0.9765781164169312, 0.004887388553470373, 0.008451880887150764, 0.01008259505033493]], [[1.0, 0.0, 0.0, 0.0], [0.9387103915214539, 0.06128958612680435, 0.0, 0.0], [0.8415918350219727, 0.0540500208735466, 0.10435819625854492, 0.0], [0.933044970035553, 0.003660219721496105, 0.03232203796505928, 0.030972827225923538]]], [[[1.0, 0.0, 0.0, 0.0], [0.7532651424407959, 0.2467348724603653, 0.0, 0.0], [0.5361011624336243, 0.33762142062187195, 0.12627744674682617, 0.0], [0.8489493727684021, 0.03734374791383743, 0.08142129331827164, 0.03228554129600525]], [[1.0, 0.0, 0.0, 0.0], [0.9166561365127563, 0.08334384858608246, 0.0, 0.0], [0.9548686742782593, 0.021359700709581375, 0.023771682754158974, 0.0], [0.8975048661231995, 0.02862684428691864, 0.027307389304041862, 0.046560950577259064]], [[1.0, 0.0, 0.0, 0.0], [0.9949731826782227, 0.005026760511100292, 0.0, 0.0], [0.9900128841400146, 0.0008919743704609573, 0.00909513235092163, 0.0], [0.9957178235054016, 0.00019670737674459815, 0.000553853518795222, 0.003531629452481866]], [[1.0, 0.0, 0.0, 0.0], [0.8989108204841614, 0.10108920931816101, 0.0, 0.0], [0.9067983031272888, 0.04304993897676468, 0.05015173554420471, 0.0], [0.7771351933479309, 0.04475653916597366, 0.09799793362617493, 0.08011035621166229]], [[1.0, 0.0, 0.0, 0.0], [0.9430936574935913, 0.056906331330537796, 0.0, 0.0], [0.8799252510070801, 0.05076925456523895, 0.06930546462535858, 0.0], [0.8979466557502747, 0.02613394893705845, 0.052693553268909454, 0.02322581224143505]], [[1.0, 0.0, 0.0, 0.0], [0.9760996103286743, 0.023900361731648445, 0.0, 0.0], [0.9392827153205872, 0.03243979066610336, 0.028277602046728134, 0.0], [0.8911391496658325, 0.013232375495135784, 0.01935073733329773, 0.07627781480550766]], [[1.0, 0.0, 0.0, 0.0], [0.9497122764587402, 0.05028776824474335, 0.0, 0.0], [0.8947458267211914, 0.04086245596408844, 0.06439172476530075, 0.0], [0.8406986594200134, 0.05102101340889931, 0.07181727886199951, 0.03646305575966835]], [[1.0, 0.0, 0.0, 0.0], [0.9661574363708496, 0.033842600882053375, 0.0, 0.0], [0.9519318342208862, 0.014750445261597633, 0.033317647874355316, 0.0], [0.9648382067680359, 0.00796716008335352, 0.0058327834121882915, 0.021361902356147766]], [[1.0, 0.0, 0.0, 0.0], [0.9338074326515198, 0.06619256734848022, 0.0, 0.0], [0.8085085153579712, 0.0642566978931427, 0.1272347867488861, 0.0], [0.16992709040641785, 0.030213594436645508, 0.7225316166877747, 0.07732769846916199]], [[1.0, 0.0, 0.0, 0.0], [0.9590391516685486, 0.040960874408483505, 0.0, 0.0], [0.9500468969345093, 0.020646605640649796, 0.029306527227163315, 0.0], [0.9257848858833313, 0.013085849583148956, 0.02678409032523632, 0.03434518352150917]], [[1.0, 0.0, 0.0, 0.0], [0.9878997206687927, 0.012100311927497387, 0.0, 0.0], [0.9930329322814941, 0.0018557860748842359, 0.00511127570644021, 0.0], [0.9808052778244019, 0.0042521776631474495, 0.007420067209750414, 0.00752241862937808]], [[1.0, 0.0, 0.0, 0.0], [0.9426974058151245, 0.05730258673429489, 0.0, 0.0], [0.9803798198699951, 0.008619184605777264, 0.011001067236065865, 0.0], [0.9880736470222473, 0.003052676562219858, 0.0016091048019006848, 0.007264540530741215]]], [[[1.0, 0.0, 0.0, 0.0], [0.9781160354614258, 0.02188396081328392, 0.0, 0.0], [0.9550318121910095, 0.024402571842074394, 0.02056562528014183, 0.0], [0.9107377529144287, 0.018443511798977852, 0.01667059026658535, 0.05414821207523346]], [[1.0, 0.0, 0.0, 0.0], [0.9899780750274658, 0.010021965019404888, 0.0, 0.0], [0.9549298286437988, 0.01071605458855629, 0.03435412794351578, 0.0], [0.9833542704582214, 0.005160455126315355, 0.0034756402019411325, 0.008009681478142738]], [[1.0, 0.0, 0.0, 0.0], [0.9222554564476013, 0.0777445062994957, 0.0, 0.0], [0.8433677554130554, 0.08172698318958282, 0.07490534335374832, 0.0], [0.7691418528556824, 0.08660437166690826, 0.10209178179502487, 0.042162008583545685]], [[1.0, 0.0, 0.0, 0.0], [0.892522931098938, 0.107477106153965, 0.0, 0.0], [0.9139972925186157, 0.0663105919957161, 0.01969211921095848, 0.0], [0.8623471856117249, 0.08329159021377563, 0.03435467928647995, 0.020006604492664337]], [[1.0, 0.0, 0.0, 0.0], [0.9421943426132202, 0.057805608958005905, 0.0, 0.0], [0.7986444234848022, 0.07576052844524384, 0.1255951076745987, 0.0], [0.8672449588775635, 0.019302574917674065, 0.07896360754966736, 0.03448893129825592]], [[1.0, 0.0, 0.0, 0.0], [0.9300352334976196, 0.06996476650238037, 0.0, 0.0], [0.8411353826522827, 0.06066778674721718, 0.09819687157869339, 0.0], [0.5995358824729919, 0.07636238634586334, 0.24590729176998138, 0.07819453626871109]], [[1.0, 0.0, 0.0, 0.0], [0.9712153077125549, 0.028784679248929024, 0.0, 0.0], [0.9529134035110474, 0.007776235695928335, 0.039310432970523834, 0.0], [0.9556993246078491, 0.005253554787486792, 0.014469185844063759, 0.024577846750617027]], [[1.0, 0.0, 0.0, 0.0], [0.9239384531974792, 0.07606157660484314, 0.0, 0.0], [0.8073780536651611, 0.08800719678401947, 0.10461478680372238, 0.0], [0.7608399391174316, 0.012566562741994858, 0.1306591033935547, 0.09593447297811508]], [[1.0, 0.0, 0.0, 0.0], [0.8811191916465759, 0.11888083815574646, 0.0, 0.0], [0.9164563417434692, 0.05789247900247574, 0.025651125237345695, 0.0], [0.7135641574859619, 0.10587184131145477, 0.10047464072704315, 0.08008938282728195]], [[1.0, 0.0, 0.0, 0.0], [0.865466833114624, 0.13453324139118195, 0.0, 0.0], [0.8325852155685425, 0.0864582508802414, 0.08095663785934448, 0.0], [0.5361157059669495, 0.14485035836696625, 0.20737196505069733, 0.11166204512119293]], [[1.0, 0.0, 0.0, 0.0], [0.8872929811477661, 0.1127069815993309, 0.0, 0.0], [0.899941086769104, 0.04387158900499344, 0.056187357753515244, 0.0], [0.8585909605026245, 0.029410896822810173, 0.04990166798233986, 0.06209652125835419]], [[1.0, 0.0, 0.0, 0.0], [0.9773025512695312, 0.02269742824137211, 0.0, 0.0], [0.9572385549545288, 0.021574916318058968, 0.021186504513025284, 0.0], [0.9247452020645142, 0.036420419812202454, 0.027243252843618393, 0.011591106653213501]]], [[[1.0, 0.0, 0.0, 0.0], [0.9073630571365356, 0.09263689815998077, 0.0, 0.0], [0.8633517622947693, 0.08370470255613327, 0.052943550050258636, 0.0], [0.42417922616004944, 0.16605573892593384, 0.2755797207355499, 0.13418538868427277]], [[1.0, 0.0, 0.0, 0.0], [0.985194981098175, 0.014805021695792675, 0.0, 0.0], [0.9667770266532898, 0.0162830650806427, 0.01693999394774437, 0.0], [0.9605299830436707, 0.0037583536468446255, 0.002912719501182437, 0.032798901200294495]], [[1.0, 0.0, 0.0, 0.0], [0.9388379454612732, 0.06116204708814621, 0.0, 0.0], [0.8815736770629883, 0.08184802532196045, 0.03657837212085724, 0.0], [0.6175433993339539, 0.1842673420906067, 0.16557322442531586, 0.032616063952445984]], [[1.0, 0.0, 0.0, 0.0], [0.8391493558883667, 0.1608506143093109, 0.0, 0.0], [0.7318846583366394, 0.12435775250196457, 0.1437576413154602, 0.0], [0.7835802435874939, 0.02795291692018509, 0.15891575813293457, 0.02955106645822525]], [[1.0, 0.0, 0.0, 0.0], [0.9620153307914734, 0.03798465058207512, 0.0, 0.0], [0.9300343990325928, 0.032783638685941696, 0.037181973457336426, 0.0], [0.9379732608795166, 0.027875877916812897, 0.02826903760433197, 0.00588188786059618]], [[1.0, 0.0, 0.0, 0.0], [0.9568069577217102, 0.043193068355321884, 0.0, 0.0], [0.9004090428352356, 0.04821838438510895, 0.05137252435088158, 0.0], [0.8455994725227356, 0.04955178499221802, 0.05498410388827324, 0.04986468330025673]], [[1.0, 0.0, 0.0, 0.0], [0.9763625264167786, 0.023637479171156883, 0.0, 0.0], [0.9349883794784546, 0.0352482870221138, 0.029763314872980118, 0.0], [0.9335187673568726, 0.039609454572200775, 0.021343547850847244, 0.005528231151401997]], [[1.0, 0.0, 0.0, 0.0], [0.9593993425369263, 0.040600668638944626, 0.0, 0.0], [0.9188076257705688, 0.03174203634262085, 0.04945032298564911, 0.0], [0.9076725244522095, 0.015262854285538197, 0.03661103919148445, 0.04045350104570389]], [[1.0, 0.0, 0.0, 0.0], [0.9688215255737305, 0.031178466975688934, 0.0, 0.0], [0.9666492342948914, 0.017512597143650055, 0.015838123857975006, 0.0], [0.8833913207054138, 0.051610320806503296, 0.05184532329440117, 0.013153048232197762]], [[1.0, 0.0, 0.0, 0.0], [0.9804984927177429, 0.01950152963399887, 0.0, 0.0], [0.953402042388916, 0.014717183075845242, 0.03188076987862587, 0.0], [0.9505434632301331, 0.02538631483912468, 0.020113958045840263, 0.00395620334893465]], [[1.0, 0.0, 0.0, 0.0], [0.9581118226051331, 0.04188825190067291, 0.0, 0.0], [0.7625529170036316, 0.09703418612480164, 0.14041292667388916, 0.0], [0.7618116140365601, 0.03211081773042679, 0.09744568914175034, 0.10863178968429565]], [[1.0, 0.0, 0.0, 0.0], [0.9889003038406372, 0.011099740862846375, 0.0, 0.0], [0.9859681129455566, 0.007783365435898304, 0.006248443387448788, 0.0], [0.964647114276886, 0.019865216687321663, 0.011471571400761604, 0.004016125109046698]]], [[[1.0, 0.0, 0.0, 0.0], [0.8864973783493042, 0.113502636551857, 0.0, 0.0], [0.8789259195327759, 0.0932716354727745, 0.027802418917417526, 0.0], [0.7940932512283325, 0.12063684314489365, 0.07414542883634567, 0.01112454105168581]], [[1.0, 0.0, 0.0, 0.0], [0.9543800354003906, 0.04562002420425415, 0.0, 0.0], [0.9232466220855713, 0.03939611837267876, 0.0373571552336216, 0.0], [0.9503932595252991, 0.023855185136198997, 0.01886543445289135, 0.006886076647788286]], [[1.0, 0.0, 0.0, 0.0], [0.9586296677589417, 0.041370317339897156, 0.0, 0.0], [0.8613924980163574, 0.07946491241455078, 0.0591425783932209, 0.0], [0.8320450782775879, 0.08810406178236008, 0.06639304757118225, 0.013457763008773327]], [[1.0, 0.0, 0.0, 0.0], [0.9581695795059204, 0.041830457746982574, 0.0, 0.0], [0.8633371591567993, 0.09287993609905243, 0.04378292337059975, 0.0], [0.9051235318183899, 0.04865259304642677, 0.022762445732951164, 0.023461459204554558]], [[1.0, 0.0, 0.0, 0.0], [0.971261739730835, 0.028738204389810562, 0.0, 0.0], [0.84889155626297, 0.061148639768362045, 0.0899597778916359, 0.0], [0.7304919362068176, 0.07432588189840317, 0.09967825561761856, 0.09550387412309647]], [[1.0, 0.0, 0.0, 0.0], [0.9071662425994873, 0.09283369779586792, 0.0, 0.0], [0.6931465268135071, 0.1139979362487793, 0.19285555183887482, 0.0], [0.8986860513687134, 0.022321369498968124, 0.0429045669734478, 0.03608804941177368]], [[1.0, 0.0, 0.0, 0.0], [0.9293556809425354, 0.07064434140920639, 0.0, 0.0], [0.8367434144020081, 0.10872092843055725, 0.054535701870918274, 0.0], [0.8608494997024536, 0.07123038917779922, 0.05457840487360954, 0.01334172673523426]], [[1.0, 0.0, 0.0, 0.0], [0.9322729706764221, 0.06772702187299728, 0.0, 0.0], [0.8862116932868958, 0.04236219823360443, 0.07142603397369385, 0.0], [0.804527223110199, 0.040870726108551025, 0.0903048887848854, 0.06429722160100937]], [[1.0, 0.0, 0.0, 0.0], [0.9781882762908936, 0.021811723709106445, 0.0, 0.0], [0.972743034362793, 0.013820390217006207, 0.013436590321362019, 0.0], [0.9758850932121277, 0.0052148327231407166, 0.005642260890454054, 0.013257873244583607]], [[1.0, 0.0, 0.0, 0.0], [0.7523583769798279, 0.24764156341552734, 0.0, 0.0], [0.5019503235816956, 0.1640997976064682, 0.33394989371299744, 0.0], [0.7590861320495605, 0.0437958687543869, 0.12566648423671722, 0.07145153731107712]], [[1.0, 0.0, 0.0, 0.0], [0.9554508328437805, 0.044549185782670975, 0.0, 0.0], [0.9342920780181885, 0.03649477660655975, 0.02921314164996147, 0.0], [0.9238194823265076, 0.03890111297369003, 0.03015044517815113, 0.007128950208425522]], [[1.0, 0.0, 0.0, 0.0], [0.9043543934822083, 0.09564556926488876, 0.0, 0.0], [0.9300746321678162, 0.043845705687999725, 0.026079723611474037, 0.0], [0.7731170654296875, 0.050871916115283966, 0.11076317727565765, 0.0652478039264679]]], [[[1.0, 0.0, 0.0, 0.0], [0.6846181154251099, 0.31538185477256775, 0.0, 0.0], [0.3272261619567871, 0.3136214017868042, 0.3591524362564087, 0.0], [0.28873831033706665, 0.20657342672348022, 0.20798607170581818, 0.29670223593711853]], [[1.0, 0.0, 0.0, 0.0], [0.9312141537666321, 0.0687859058380127, 0.0, 0.0], [0.8793478012084961, 0.06257884949445724, 0.058073315769433975, 0.0], [0.8864972591400146, 0.0425117202103138, 0.034507401287555695, 0.03648369759321213]], [[1.0, 0.0, 0.0, 0.0], [0.9740089178085327, 0.025991037487983704, 0.0, 0.0], [0.8993344902992249, 0.05028178170323372, 0.050383713096380234, 0.0], [0.9128904938697815, 0.027618031948804855, 0.04365304857492447, 0.015838420018553734]], [[1.0, 0.0, 0.0, 0.0], [0.8313109874725342, 0.16868899762630463, 0.0, 0.0], [0.8412584066390991, 0.08335168659687042, 0.07538992911577225, 0.0], [0.8332040309906006, 0.04624852538108826, 0.07621588557958603, 0.044331617653369904]], [[1.0, 0.0, 0.0, 0.0], [0.8731979131698608, 0.12680207192897797, 0.0, 0.0], [0.8157558441162109, 0.09303369373083115, 0.09121055901050568, 0.0], [0.7348884344100952, 0.06551358103752136, 0.06824001669883728, 0.13135792315006256]], [[1.0, 0.0, 0.0, 0.0], [0.9549729824066162, 0.045027025043964386, 0.0, 0.0], [0.9184066653251648, 0.04648442938923836, 0.03510890528559685, 0.0], [0.9598978757858276, 0.018655594438314438, 0.011372693814337254, 0.01007384154945612]], [[1.0, 0.0, 0.0, 0.0], [0.9425029754638672, 0.0574970543384552, 0.0, 0.0], [0.8904843926429749, 0.059747856110334396, 0.04976780712604523, 0.0], [0.9303671717643738, 0.03467365354299545, 0.026911389082670212, 0.008047860115766525]], [[1.0, 0.0, 0.0, 0.0], [0.8861631155014038, 0.1138368770480156, 0.0, 0.0], [0.7801804542541504, 0.09589225053787231, 0.12392730265855789, 0.0], [0.813708484172821, 0.0657411441206932, 0.061849839985370636, 0.05870051309466362]], [[1.0, 0.0, 0.0, 0.0], [5.394863910623826e-05, 0.9999459981918335, 0.0, 0.0], [1.0295632819179446e-05, 0.5862687826156616, 0.4137209951877594, 0.0], [0.00017180161376018077, 0.15909713506698608, 0.3270132541656494, 0.5137178301811218]], [[1.0, 0.0, 0.0, 0.0], [0.9380736351013184, 0.06192633509635925, 0.0, 0.0], [0.9011828303337097, 0.05448286607861519, 0.044334277510643005, 0.0], [0.9323163032531738, 0.03217263147234917, 0.017909713089466095, 0.01760145090520382]], [[1.0, 0.0, 0.0, 0.0], [0.7672830820083618, 0.232716903090477, 0.0, 0.0], [0.5923321843147278, 0.17692995071411133, 0.2307378500699997, 0.0], [0.7143336534500122, 0.06842997670173645, 0.1164291575551033, 0.10080726444721222]], [[1.0, 0.0, 0.0, 0.0], [0.9365187287330627, 0.06348133087158203, 0.0, 0.0], [0.8265508413314819, 0.09784789383411407, 0.07560129463672638, 0.0], [0.7361746430397034, 0.07360215485095978, 0.0997605249285698, 0.09046268463134766]]]], \"left_text\": [\"Machine\", \" Learning\", \" algorithms\", \" are\"], \"right_text\": [\"Machine\", \" Learning\", \" algorithms\", \" are\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-6f380e475bd44dc99a57a16401bd9f53\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0], [0.8369596600532532, 0.16304033994674683, 0.0, 0.0], [0.5454381704330444, 0.3083677887916565, 0.1461939960718155, 0.0], [0.495052307844162, 0.2794095277786255, 0.14270007610321045, 0.0828380137681961]], [[1.0, 0.0, 0.0, 0.0], [0.000313624826958403, 0.9996863603591919, 0.0, 0.0], [0.00028791805380024016, 0.00802256353199482, 0.9916894435882568, 0.0], [0.0005425689159892499, 0.0032627112232148647, 0.0006531100952997804, 0.9955416321754456]], [[1.0, 0.0, 0.0, 0.0], [0.8448778390884399, 0.15512219071388245, 0.0, 0.0], [0.5251489877700806, 0.275814414024353, 0.19903653860092163, 0.0], [0.36849015951156616, 0.1658337414264679, 0.17271070182323456, 0.2929653823375702]], [[1.0, 0.0, 0.0, 0.0], [0.24503926932811737, 0.7549607157707214, 0.0, 0.0], [0.07685161381959915, 0.007359172683209181, 0.9157891869544983, 0.0], [0.05555616691708565, 0.036348260939121246, 0.06720822304487228, 0.8408873677253723]], [[1.0, 0.0, 0.0, 0.0], [0.9365429878234863, 0.06345698982477188, 0.0, 0.0], [0.3796883821487427, 0.11549505591392517, 0.5048165321350098, 0.0], [0.25266125798225403, 0.11302568763494492, 0.4062349796295166, 0.22807802259922028]], [[1.0, 0.0, 0.0, 0.0], [0.08450809866189957, 0.9154918789863586, 0.0, 0.0], [0.035101741552352905, 0.00024448824115097523, 0.9646537899971008, 0.0], [0.047608859837055206, 0.0005061915726400912, 0.0009468193165957928, 0.9509381055831909]], [[1.0, 0.0, 0.0, 0.0], [0.9110549688339233, 0.08894503861665726, 0.0, 0.0], [0.48893216252326965, 0.17591167986392975, 0.3351562023162842, 0.0], [0.38058727979660034, 0.22310711443424225, 0.3622194528579712, 0.03408609330654144]], [[1.0, 0.0, 0.0, 0.0], [0.9978750944137573, 0.0021248599514365196, 0.0, 0.0], [0.3374008238315582, 0.5339188575744629, 0.12868033349514008, 0.0], [0.17422336339950562, 0.228385791182518, 0.40501347184181213, 0.19237743318080902]], [[1.0, 0.0, 0.0, 0.0], [0.9152600169181824, 0.08473993092775345, 0.0, 0.0], [0.5479149222373962, 0.3631327748298645, 0.08895225822925568, 0.0], [0.16942870616912842, 0.08551950752735138, 0.0642383024096489, 0.6808134913444519]], [[1.0, 0.0, 0.0, 0.0], [0.9147995114326477, 0.0852004662156105, 0.0, 0.0], [0.7048966288566589, 0.21635966002941132, 0.07874368876218796, 0.0], [0.4142463505268097, 0.14826752245426178, 0.17459677159786224, 0.2628893554210663]], [[1.0, 0.0, 0.0, 0.0], [0.6071661114692688, 0.3928338289260864, 0.0, 0.0], [0.46326571702957153, 0.18070173263549805, 0.35603249073028564, 0.0], [0.29799604415893555, 0.1267867088317871, 0.11243902146816254, 0.4627783000469208]], [[1.0, 0.0, 0.0, 0.0], [0.6133790612220764, 0.38662096858024597, 0.0, 0.0], [0.33036354184150696, 0.20231738686561584, 0.4673191010951996, 0.0], [0.3790343701839447, 0.14877310395240784, 0.2053280770778656, 0.26686444878578186]]], [[[1.0, 0.0, 0.0, 0.0], [0.9704445600509644, 0.029555508866906166, 0.0, 0.0], [0.6386247277259827, 0.22806428372859955, 0.1333109438419342, 0.0], [0.37808969616889954, 0.1540047824382782, 0.23913003504276276, 0.22877545654773712]], [[1.0, 0.0, 0.0, 0.0], [0.9330123066902161, 0.06698770821094513, 0.0, 0.0], [0.7352873682975769, 0.13050943613052368, 0.1342032104730606, 0.0], [0.5596781373023987, 0.1153513714671135, 0.1315806657075882, 0.19338980317115784]], [[1.0, 0.0, 0.0, 0.0], [0.974357008934021, 0.025642987340688705, 0.0, 0.0], [0.6994037628173828, 0.059934210032224655, 0.24066203832626343, 0.0], [0.493990033864975, 0.04794042557477951, 0.17723573744297028, 0.2808338701725006]], [[1.0, 0.0, 0.0, 0.0], [0.6114571690559387, 0.3885428309440613, 0.0, 0.0], [0.6385886669158936, 0.17295996844768524, 0.1884513795375824, 0.0], [0.5487473011016846, 0.13837896287441254, 0.15583735704421997, 0.15703636407852173]], [[1.0, 0.0, 0.0, 0.0], [0.9063447117805481, 0.09365527331829071, 0.0, 0.0], [0.7631184458732605, 0.10433613508939743, 0.13254539668560028, 0.0], [0.6749664545059204, 0.10557929426431656, 0.12621375918388367, 0.09324046224355698]], [[1.0, 0.0, 0.0, 0.0], [0.8225984573364258, 0.1774015873670578, 0.0, 0.0], [0.494573712348938, 0.2700279951095581, 0.2353982776403427, 0.0], [0.4025273323059082, 0.08602583408355713, 0.05536993592977524, 0.45607680082321167]], [[1.0, 0.0, 0.0, 0.0], [0.9537613987922668, 0.04623857140541077, 0.0, 0.0], [0.6869997382164001, 0.17357608675956726, 0.13942420482635498, 0.0], [0.8128571510314941, 0.07806374132633209, 0.058629702776670456, 0.05044940486550331]], [[1.0, 0.0, 0.0, 0.0], [0.9553384184837341, 0.04466155916452408, 0.0, 0.0], [0.7505393624305725, 0.17406539618968964, 0.07539532333612442, 0.0], [0.6242748498916626, 0.10723694413900375, 0.1399562656879425, 0.12853190302848816]], [[1.0, 0.0, 0.0, 0.0], [0.8932788372039795, 0.10672123730182648, 0.0, 0.0], [0.7336891889572144, 0.10167518258094788, 0.16463567316532135, 0.0], [0.5917772650718689, 0.10893679410219193, 0.12896184623241425, 0.17032407224178314]], [[1.0, 0.0, 0.0, 0.0], [0.9785101413726807, 0.02148984931409359, 0.0, 0.0], [0.8446694016456604, 0.07469841092824936, 0.08063214272260666, 0.0], [0.7354145646095276, 0.05895343795418739, 0.0681559219956398, 0.13747596740722656]], [[1.0, 0.0, 0.0, 0.0], [0.00028119742637500167, 0.9997187256813049, 0.0, 0.0], [0.0008738978649489582, 0.5217098593711853, 0.4774162769317627, 0.0], [0.0009776718216016889, 0.3428777754306793, 0.33847033977508545, 0.3176741898059845]], [[1.0, 0.0, 0.0, 0.0], [0.29874947667121887, 0.7012505531311035, 0.0, 0.0], [0.1370234489440918, 0.029669342562556267, 0.8333072066307068, 0.0], [0.09141987562179565, 0.005299035459756851, 0.0023187785409390926, 0.9009623527526855]]], [[[1.0, 0.0, 0.0, 0.0], [0.979323148727417, 0.020676879212260246, 0.0, 0.0], [0.8653432726860046, 0.0966615304350853, 0.03799512982368469, 0.0], [0.7161295413970947, 0.10998967289924622, 0.08727509528398514, 0.08660577982664108]], [[1.0, 0.0, 0.0, 0.0], [0.9533320665359497, 0.046667978167533875, 0.0, 0.0], [0.6956794261932373, 0.18802674114704132, 0.11629381775856018, 0.0], [0.8644037842750549, 0.021114042028784752, 0.018893064931035042, 0.09558915346860886]], [[1.0, 0.0, 0.0, 0.0], [0.9927532076835632, 0.007246746215969324, 0.0, 0.0], [0.3032039403915405, 0.64506596326828, 0.05173014849424362, 0.0], [0.32077324390411377, 0.1233762577176094, 0.3800252377986908, 0.17582522332668304]], [[1.0, 0.0, 0.0, 0.0], [0.9649205207824707, 0.035079460591077805, 0.0, 0.0], [0.6518253684043884, 0.2649356424808502, 0.08323896676301956, 0.0], [0.5497181415557861, 0.33758386969566345, 0.05332303047180176, 0.05937488004565239]], [[1.0, 0.0, 0.0, 0.0], [0.9978498220443726, 0.0021502331364899874, 0.0, 0.0], [0.916073203086853, 0.035401538014411926, 0.04852518439292908, 0.0], [0.7424127459526062, 0.05997372046113014, 0.029520198702812195, 0.16809333860874176]], [[1.0, 0.0, 0.0, 0.0], [0.982830286026001, 0.017169665545225143, 0.0, 0.0], [0.7756311297416687, 0.16884750127792358, 0.055521368980407715, 0.0], [0.4917299449443817, 0.09442475438117981, 0.15344028174877167, 0.260405033826828]], [[1.0, 0.0, 0.0, 0.0], [0.957459032535553, 0.04254094883799553, 0.0, 0.0], [0.8769592642784119, 0.06309546530246735, 0.059945233166217804, 0.0], [0.8289990425109863, 0.06033581495285034, 0.04139074683189392, 0.0692744255065918]], [[1.0, 0.0, 0.0, 0.0], [0.7742899060249329, 0.22571012377738953, 0.0, 0.0], [0.44242358207702637, 0.15451042354106903, 0.403065949678421, 0.0], [0.3363172113895416, 0.08960270881652832, 0.26217737793922424, 0.3119026720523834]], [[1.0, 0.0, 0.0, 0.0], [0.975498378276825, 0.024501606822013855, 0.0, 0.0], [0.6640846133232117, 0.24570739269256592, 0.09020791947841644, 0.0], [0.4707483649253845, 0.13731087744235992, 0.1213899701833725, 0.27055081725120544]], [[1.0, 0.0, 0.0, 0.0], [0.9771293997764587, 0.022870643064379692, 0.0, 0.0], [0.5135151743888855, 0.3658927083015442, 0.12059206515550613, 0.0], [0.3294655680656433, 0.15208598971366882, 0.4792048931121826, 0.03924347087740898]], [[1.0, 0.0, 0.0, 0.0], [0.834203839302063, 0.1657961755990982, 0.0, 0.0], [0.5445191860198975, 0.15962029993534088, 0.29586052894592285, 0.0], [0.47055649757385254, 0.1510101705789566, 0.2120228111743927, 0.16641049087047577]], [[1.0, 0.0, 0.0, 0.0], [0.947394073009491, 0.05260597914457321, 0.0, 0.0], [0.8473399877548218, 0.05213896930217743, 0.10052114725112915, 0.0], [0.7784276008605957, 0.051031529903411865, 0.08721314370632172, 0.08332774043083191]]], [[[1.0, 0.0, 0.0, 0.0], [0.9902021288871765, 0.009797906503081322, 0.0, 0.0], [0.974983274936676, 0.0026431484147906303, 0.022373542189598083, 0.0], [0.980229377746582, 0.0002615370904095471, 0.0005459703970700502, 0.018963150680065155]], [[1.0, 0.0, 0.0, 0.0], [0.9891428351402283, 0.010857130400836468, 0.0, 0.0], [0.975196361541748, 0.01235035341233015, 0.012453315779566765, 0.0], [0.9287400841712952, 0.007586255203932524, 0.001763215521350503, 0.061910390853881836]], [[1.0, 0.0, 0.0, 0.0], [0.893498420715332, 0.10650157183408737, 0.0, 0.0], [0.6191083192825317, 0.2279088944196701, 0.15298277139663696, 0.0], [0.31921836733818054, 0.3756026029586792, 0.17115254700183868, 0.13402636349201202]], [[1.0, 0.0, 0.0, 0.0], [0.8705539107322693, 0.1294460892677307, 0.0, 0.0], [0.7996733784675598, 0.14678318798542023, 0.053543440997600555, 0.0], [0.8236583471298218, 0.0546727254986763, 0.06270219385623932, 0.0589667446911335]], [[1.0, 0.0, 0.0, 0.0], [0.998528003692627, 0.0014719455502927303, 0.0, 0.0], [0.9905322790145874, 0.006602975074201822, 0.002864750102162361, 0.0], [0.9665279388427734, 0.003725797636434436, 0.010092132724821568, 0.01965402252972126]], [[1.0, 0.0, 0.0, 0.0], [0.9768734574317932, 0.023126551881432533, 0.0, 0.0], [0.8967821598052979, 0.0488673597574234, 0.05435044318437576, 0.0], [0.9002225995063782, 0.02542898990213871, 0.041070606559515, 0.03327779099345207]], [[1.0, 0.0, 0.0, 0.0], [0.9477744698524475, 0.052225545048713684, 0.0, 0.0], [0.4087452292442322, 0.4693022668361664, 0.12195252627134323, 0.0], [0.259976863861084, 0.4564320147037506, 0.19631369411945343, 0.08727742731571198]], [[1.0, 0.0, 0.0, 0.0], [0.8056485652923584, 0.19435137510299683, 0.0, 0.0], [0.21869415044784546, 0.6502187252044678, 0.13108715415000916, 0.0], [0.16758395731449127, 0.19799543917179108, 0.5688384175300598, 0.06558214873075485]], [[1.0, 0.0, 0.0, 0.0], [0.9566323757171631, 0.04336763918399811, 0.0, 0.0], [0.7401798963546753, 0.15399986505508423, 0.10582025349140167, 0.0], [0.4607292413711548, 0.16108983755111694, 0.040174126625061035, 0.33800676465034485]], [[1.0, 0.0, 0.0, 0.0], [0.994489312171936, 0.005510695278644562, 0.0, 0.0], [0.9145376086235046, 0.05818839743733406, 0.027273952960968018, 0.0], [0.7961251139640808, 0.022507833316922188, 0.007412086706608534, 0.1739550083875656]], [[1.0, 0.0, 0.0, 0.0], [0.9707838296890259, 0.029216134920716286, 0.0, 0.0], [0.7331598997116089, 0.08832243084907532, 0.17851771414279938, 0.0], [0.8049229383468628, 0.02779119275510311, 0.08374433219432831, 0.08354155719280243]], [[1.0, 0.0, 0.0, 0.0], [0.9712401628494263, 0.028759876266121864, 0.0, 0.0], [0.845210075378418, 0.04490312933921814, 0.10988675057888031, 0.0], [0.7398038506507874, 0.037047337740659714, 0.0495198629796505, 0.17362898588180542]]], [[[1.0, 0.0, 0.0, 0.0], [0.9693757891654968, 0.030624130740761757, 0.0, 0.0], [0.9188656210899353, 0.03805970773100853, 0.043074700981378555, 0.0], [0.9319638013839722, 0.0013976383488625288, 0.005987958051264286, 0.06065056100487709]], [[1.0, 0.0, 0.0, 0.0], [0.9800292253494263, 0.01997075229883194, 0.0, 0.0], [0.9718928337097168, 0.003747849026694894, 0.024359365925192833, 0.0], [0.9573526382446289, 0.0025618774816393852, 0.008242323994636536, 0.03184313699603081]], [[1.0, 0.0, 0.0, 0.0], [0.9867386817932129, 0.013261334039270878, 0.0, 0.0], [0.9557056427001953, 0.019744232296943665, 0.024550138041377068, 0.0], [0.9501595497131348, 0.008854535408318043, 0.01007052045315504, 0.030915414914488792]], [[1.0, 0.0, 0.0, 0.0], [0.8265204429626465, 0.1734795719385147, 0.0, 0.0], [0.6355267763137817, 0.25672414898872375, 0.10774916410446167, 0.0], [0.18620295822620392, 0.040084898471832275, 0.7422723770141602, 0.031439781188964844]], [[1.0, 0.0, 0.0, 0.0], [0.7905768156051636, 0.20942318439483643, 0.0, 0.0], [0.519731342792511, 0.18113018572330475, 0.29913851618766785, 0.0], [0.7743175625801086, 0.05341408774256706, 0.12167904525995255, 0.05058928206562996]], [[1.0, 0.0, 0.0, 0.0], [0.9885457158088684, 0.011454344727098942, 0.0, 0.0], [0.8765727877616882, 0.03792751580476761, 0.08549966663122177, 0.0], [0.903056263923645, 0.023861736059188843, 0.04364444315433502, 0.029437562450766563]], [[1.0, 0.0, 0.0, 0.0], [0.9562316536903381, 0.04376841336488724, 0.0, 0.0], [0.8558523058891296, 0.11495095491409302, 0.029196711257100105, 0.0], [0.6696529984474182, 0.16483807563781738, 0.1096738949418068, 0.05583502724766731]], [[1.0, 0.0, 0.0, 0.0], [0.9639875292778015, 0.0360124446451664, 0.0, 0.0], [0.5806638598442078, 0.03554213047027588, 0.38379406929016113, 0.0], [0.4580995440483093, 0.012987391091883183, 0.1599356234073639, 0.36897745728492737]], [[1.0, 0.0, 0.0, 0.0], [0.961618959903717, 0.038381047546863556, 0.0, 0.0], [0.9179849624633789, 0.030934102833271027, 0.051080986857414246, 0.0], [0.8626840114593506, 0.012464135885238647, 0.0717041939496994, 0.053147658705711365]], [[1.0, 0.0, 0.0, 0.0], [0.9893536567687988, 0.010646392591297626, 0.0, 0.0], [0.9517208933830261, 0.00560116209089756, 0.04267798736691475, 0.0], [0.9782204031944275, 0.0009760136599652469, 0.005679030902683735, 0.015124460682272911]], [[1.0, 0.0, 0.0, 0.0], [0.9727651476860046, 0.027234844863414764, 0.0, 0.0], [0.866966724395752, 0.07700687646865845, 0.056026410311460495, 0.0], [0.9648429751396179, 0.014742870815098286, 0.00617409311234951, 0.01424003392457962]], [[1.0, 0.0, 0.0, 0.0], [0.9999716281890869, 2.8336497052805498e-05, 0.0, 0.0], [1.1262841326242778e-06, 0.9998111128807068, 0.0001878697657957673, 0.0], [8.906245518858213e-09, 1.1331393579894211e-05, 0.999985933303833, 2.7121138828078983e-06]]], [[[1.0, 0.0, 0.0, 0.0], [0.9836140871047974, 0.016385985538363457, 0.0, 0.0], [0.9765778183937073, 0.009898822754621506, 0.013523346744477749, 0.0], [0.9769649505615234, 0.002553685335442424, 0.001368800294585526, 0.01911252923309803]], [[1.0, 0.0, 0.0, 0.0], [0.9999068975448608, 9.312301699537784e-05, 0.0, 0.0], [0.9983245730400085, 4.8447847802890465e-05, 0.001627017860300839, 0.0], [0.9986074566841125, 5.2555124057107605e-06, 1.3999418115417939e-05, 0.0013733254745602608]], [[1.0, 0.0, 0.0, 0.0], [0.879912793636322, 0.12008718401193619, 0.0, 0.0], [0.6022446155548096, 0.27633413672447205, 0.12142125517129898, 0.0], [0.6311676502227783, 0.08535166829824448, 0.24289457499980927, 0.04058617725968361]], [[1.0, 0.0, 0.0, 0.0], [0.9340515732765198, 0.06594836711883545, 0.0, 0.0], [0.5871796607971191, 0.25288164615631104, 0.15993866324424744, 0.0], [0.6978021264076233, 0.09078722447156906, 0.08866176754236221, 0.12274889647960663]], [[1.0, 0.0, 0.0, 0.0], [0.975918173789978, 0.024081889539957047, 0.0, 0.0], [0.8064600825309753, 0.07989509403705597, 0.11364487558603287, 0.0], [0.898098886013031, 0.013392063789069653, 0.04240615665912628, 0.04610288143157959]], [[1.0, 0.0, 0.0, 0.0], [0.9912323355674744, 0.00876766350120306, 0.0, 0.0], [0.9758439064025879, 0.01937630958855152, 0.0047797453589737415, 0.0], [0.9574930667877197, 0.008500847965478897, 0.006429125554859638, 0.027576982975006104]], [[1.0, 0.0, 0.0, 0.0], [0.9392426609992981, 0.0607573501765728, 0.0, 0.0], [0.6449490785598755, 0.2738036811351776, 0.08124731481075287, 0.0], [0.8555845022201538, 0.005867495201528072, 0.08781339973211288, 0.05073460191488266]], [[1.0, 0.0, 0.0, 0.0], [0.9653253555297852, 0.03467467427253723, 0.0, 0.0], [0.9449016451835632, 0.023804590106010437, 0.03129380941390991, 0.0], [0.9815472364425659, 0.0012909608194604516, 0.011074836365878582, 0.00608696136623621]], [[1.0, 0.0, 0.0, 0.0], [0.9680588841438293, 0.031941067427396774, 0.0, 0.0], [0.8569985032081604, 0.06653749197721481, 0.0764639750123024, 0.0], [0.9378696084022522, 0.008969446644186974, 0.009564449079334736, 0.04359638690948486]], [[1.0, 0.0, 0.0, 0.0], [0.975807249546051, 0.02419278584420681, 0.0, 0.0], [0.9480755925178528, 0.04677429422736168, 0.005150042474269867, 0.0], [0.8044395446777344, 0.06546380370855331, 0.07469691336154938, 0.055399760603904724]], [[1.0, 0.0, 0.0, 0.0], [0.6921703815460205, 0.3078295886516571, 0.0, 0.0], [0.6430989503860474, 0.3076874613761902, 0.04921359568834305, 0.0], [0.4546832740306854, 0.183853879570961, 0.21879146993160248, 0.1426713764667511]], [[1.0, 0.0, 0.0, 0.0], [0.9623194336891174, 0.037680484354496, 0.0, 0.0], [0.8048304915428162, 0.09014122933149338, 0.10502833127975464, 0.0], [0.5883017778396606, 0.05813616141676903, 0.07127902656793594, 0.2822830080986023]]], [[[1.0, 0.0, 0.0, 0.0], [0.8478448390960693, 0.15215519070625305, 0.0, 0.0], [0.7306845784187317, 0.121076300740242, 0.1482391208410263, 0.0], [0.6748157143592834, 0.04602762684226036, 0.19763080775737762, 0.08152579516172409]], [[1.0, 0.0, 0.0, 0.0], [0.9823725819587708, 0.017627395689487457, 0.0, 0.0], [0.9468225240707397, 0.006157270632684231, 0.04702017828822136, 0.0], [0.8949708342552185, 0.02156319096684456, 0.07169516384601593, 0.011770790442824364]], [[1.0, 0.0, 0.0, 0.0], [0.9561967849731445, 0.04380320757627487, 0.0, 0.0], [0.8608885407447815, 0.08694235980510712, 0.052169013768434525, 0.0], [0.8861517906188965, 0.04828586056828499, 0.02329666167497635, 0.04226572439074516]], [[1.0, 0.0, 0.0, 0.0], [0.981881320476532, 0.018118679523468018, 0.0, 0.0], [0.9134630560874939, 0.03209998086094856, 0.05443696677684784, 0.0], [0.875910222530365, 0.024367760866880417, 0.057334378361701965, 0.04238774999976158]], [[1.0, 0.0, 0.0, 0.0], [0.9381165504455566, 0.06188347563147545, 0.0, 0.0], [0.970572292804718, 0.020803941413760185, 0.008623836562037468, 0.0], [0.8397429585456848, 0.040844790637493134, 0.024267971515655518, 0.09514429420232773]], [[1.0, 0.0, 0.0, 0.0], [0.9257916212081909, 0.07420840114355087, 0.0, 0.0], [0.8414416909217834, 0.07572581619024277, 0.08283250033855438, 0.0], [0.873722493648529, 0.039385709911584854, 0.056421391665935516, 0.03047034703195095]], [[1.0, 0.0, 0.0, 0.0], [0.9303593039512634, 0.06964066624641418, 0.0, 0.0], [0.9047715067863464, 0.0456433929502964, 0.049585066735744476, 0.0], [0.920358419418335, 0.014210919849574566, 0.013970093801617622, 0.051460664719343185]], [[1.0, 0.0, 0.0, 0.0], [0.8821121454238892, 0.11788780242204666, 0.0, 0.0], [0.8118640184402466, 0.12519629299640656, 0.06293972581624985, 0.0], [0.6577447056770325, 0.12387697398662567, 0.17867420613765717, 0.03970417007803917]], [[1.0, 0.0, 0.0, 0.0], [0.705574631690979, 0.2944253981113434, 0.0, 0.0], [0.40366578102111816, 0.4589470624923706, 0.13738717138767242, 0.0], [0.5951082706451416, 0.08372033387422562, 0.2782452404499054, 0.04292619973421097]], [[1.0, 0.0, 0.0, 0.0], [0.9989274144172668, 0.0010725656757131219, 0.0, 0.0], [0.9955834746360779, 0.0005400340305641294, 0.003876502625644207, 0.0], [0.9955409169197083, 0.0015136642614379525, 0.0010158899240195751, 0.0019296339014545083]], [[1.0, 0.0, 0.0, 0.0], [0.9712175726890564, 0.02878241427242756, 0.0, 0.0], [0.9646689891815186, 0.008357902057468891, 0.02697315439581871, 0.0], [0.9765781164169312, 0.004887388553470373, 0.008451880887150764, 0.01008259505033493]], [[1.0, 0.0, 0.0, 0.0], [0.9387103915214539, 0.06128958612680435, 0.0, 0.0], [0.8415918350219727, 0.0540500208735466, 0.10435819625854492, 0.0], [0.933044970035553, 0.003660219721496105, 0.03232203796505928, 0.030972827225923538]]], [[[1.0, 0.0, 0.0, 0.0], [0.7532651424407959, 0.2467348724603653, 0.0, 0.0], [0.5361011624336243, 0.33762142062187195, 0.12627744674682617, 0.0], [0.8489493727684021, 0.03734374791383743, 0.08142129331827164, 0.03228554129600525]], [[1.0, 0.0, 0.0, 0.0], [0.9166561365127563, 0.08334384858608246, 0.0, 0.0], [0.9548686742782593, 0.021359700709581375, 0.023771682754158974, 0.0], [0.8975048661231995, 0.02862684428691864, 0.027307389304041862, 0.046560950577259064]], [[1.0, 0.0, 0.0, 0.0], [0.9949731826782227, 0.005026760511100292, 0.0, 0.0], [0.9900128841400146, 0.0008919743704609573, 0.00909513235092163, 0.0], [0.9957178235054016, 0.00019670737674459815, 0.000553853518795222, 0.003531629452481866]], [[1.0, 0.0, 0.0, 0.0], [0.8989108204841614, 0.10108920931816101, 0.0, 0.0], [0.9067983031272888, 0.04304993897676468, 0.05015173554420471, 0.0], [0.7771351933479309, 0.04475653916597366, 0.09799793362617493, 0.08011035621166229]], [[1.0, 0.0, 0.0, 0.0], [0.9430936574935913, 0.056906331330537796, 0.0, 0.0], [0.8799252510070801, 0.05076925456523895, 0.06930546462535858, 0.0], [0.8979466557502747, 0.02613394893705845, 0.052693553268909454, 0.02322581224143505]], [[1.0, 0.0, 0.0, 0.0], [0.9760996103286743, 0.023900361731648445, 0.0, 0.0], [0.9392827153205872, 0.03243979066610336, 0.028277602046728134, 0.0], [0.8911391496658325, 0.013232375495135784, 0.01935073733329773, 0.07627781480550766]], [[1.0, 0.0, 0.0, 0.0], [0.9497122764587402, 0.05028776824474335, 0.0, 0.0], [0.8947458267211914, 0.04086245596408844, 0.06439172476530075, 0.0], [0.8406986594200134, 0.05102101340889931, 0.07181727886199951, 0.03646305575966835]], [[1.0, 0.0, 0.0, 0.0], [0.9661574363708496, 0.033842600882053375, 0.0, 0.0], [0.9519318342208862, 0.014750445261597633, 0.033317647874355316, 0.0], [0.9648382067680359, 0.00796716008335352, 0.0058327834121882915, 0.021361902356147766]], [[1.0, 0.0, 0.0, 0.0], [0.9338074326515198, 0.06619256734848022, 0.0, 0.0], [0.8085085153579712, 0.0642566978931427, 0.1272347867488861, 0.0], [0.16992709040641785, 0.030213594436645508, 0.7225316166877747, 0.07732769846916199]], [[1.0, 0.0, 0.0, 0.0], [0.9590391516685486, 0.040960874408483505, 0.0, 0.0], [0.9500468969345093, 0.020646605640649796, 0.029306527227163315, 0.0], [0.9257848858833313, 0.013085849583148956, 0.02678409032523632, 0.03434518352150917]], [[1.0, 0.0, 0.0, 0.0], [0.9878997206687927, 0.012100311927497387, 0.0, 0.0], [0.9930329322814941, 0.0018557860748842359, 0.00511127570644021, 0.0], [0.9808052778244019, 0.0042521776631474495, 0.007420067209750414, 0.00752241862937808]], [[1.0, 0.0, 0.0, 0.0], [0.9426974058151245, 0.05730258673429489, 0.0, 0.0], [0.9803798198699951, 0.008619184605777264, 0.011001067236065865, 0.0], [0.9880736470222473, 0.003052676562219858, 0.0016091048019006848, 0.007264540530741215]]], [[[1.0, 0.0, 0.0, 0.0], [0.9781160354614258, 0.02188396081328392, 0.0, 0.0], [0.9550318121910095, 0.024402571842074394, 0.02056562528014183, 0.0], [0.9107377529144287, 0.018443511798977852, 0.01667059026658535, 0.05414821207523346]], [[1.0, 0.0, 0.0, 0.0], [0.9899780750274658, 0.010021965019404888, 0.0, 0.0], [0.9549298286437988, 0.01071605458855629, 0.03435412794351578, 0.0], [0.9833542704582214, 0.005160455126315355, 0.0034756402019411325, 0.008009681478142738]], [[1.0, 0.0, 0.0, 0.0], [0.9222554564476013, 0.0777445062994957, 0.0, 0.0], [0.8433677554130554, 0.08172698318958282, 0.07490534335374832, 0.0], [0.7691418528556824, 0.08660437166690826, 0.10209178179502487, 0.042162008583545685]], [[1.0, 0.0, 0.0, 0.0], [0.892522931098938, 0.107477106153965, 0.0, 0.0], [0.9139972925186157, 0.0663105919957161, 0.01969211921095848, 0.0], [0.8623471856117249, 0.08329159021377563, 0.03435467928647995, 0.020006604492664337]], [[1.0, 0.0, 0.0, 0.0], [0.9421943426132202, 0.057805608958005905, 0.0, 0.0], [0.7986444234848022, 0.07576052844524384, 0.1255951076745987, 0.0], [0.8672449588775635, 0.019302574917674065, 0.07896360754966736, 0.03448893129825592]], [[1.0, 0.0, 0.0, 0.0], [0.9300352334976196, 0.06996476650238037, 0.0, 0.0], [0.8411353826522827, 0.06066778674721718, 0.09819687157869339, 0.0], [0.5995358824729919, 0.07636238634586334, 0.24590729176998138, 0.07819453626871109]], [[1.0, 0.0, 0.0, 0.0], [0.9712153077125549, 0.028784679248929024, 0.0, 0.0], [0.9529134035110474, 0.007776235695928335, 0.039310432970523834, 0.0], [0.9556993246078491, 0.005253554787486792, 0.014469185844063759, 0.024577846750617027]], [[1.0, 0.0, 0.0, 0.0], [0.9239384531974792, 0.07606157660484314, 0.0, 0.0], [0.8073780536651611, 0.08800719678401947, 0.10461478680372238, 0.0], [0.7608399391174316, 0.012566562741994858, 0.1306591033935547, 0.09593447297811508]], [[1.0, 0.0, 0.0, 0.0], [0.8811191916465759, 0.11888083815574646, 0.0, 0.0], [0.9164563417434692, 0.05789247900247574, 0.025651125237345695, 0.0], [0.7135641574859619, 0.10587184131145477, 0.10047464072704315, 0.08008938282728195]], [[1.0, 0.0, 0.0, 0.0], [0.865466833114624, 0.13453324139118195, 0.0, 0.0], [0.8325852155685425, 0.0864582508802414, 0.08095663785934448, 0.0], [0.5361157059669495, 0.14485035836696625, 0.20737196505069733, 0.11166204512119293]], [[1.0, 0.0, 0.0, 0.0], [0.8872929811477661, 0.1127069815993309, 0.0, 0.0], [0.899941086769104, 0.04387158900499344, 0.056187357753515244, 0.0], [0.8585909605026245, 0.029410896822810173, 0.04990166798233986, 0.06209652125835419]], [[1.0, 0.0, 0.0, 0.0], [0.9773025512695312, 0.02269742824137211, 0.0, 0.0], [0.9572385549545288, 0.021574916318058968, 0.021186504513025284, 0.0], [0.9247452020645142, 0.036420419812202454, 0.027243252843618393, 0.011591106653213501]]], [[[1.0, 0.0, 0.0, 0.0], [0.9073630571365356, 0.09263689815998077, 0.0, 0.0], [0.8633517622947693, 0.08370470255613327, 0.052943550050258636, 0.0], [0.42417922616004944, 0.16605573892593384, 0.2755797207355499, 0.13418538868427277]], [[1.0, 0.0, 0.0, 0.0], [0.985194981098175, 0.014805021695792675, 0.0, 0.0], [0.9667770266532898, 0.0162830650806427, 0.01693999394774437, 0.0], [0.9605299830436707, 0.0037583536468446255, 0.002912719501182437, 0.032798901200294495]], [[1.0, 0.0, 0.0, 0.0], [0.9388379454612732, 0.06116204708814621, 0.0, 0.0], [0.8815736770629883, 0.08184802532196045, 0.03657837212085724, 0.0], [0.6175433993339539, 0.1842673420906067, 0.16557322442531586, 0.032616063952445984]], [[1.0, 0.0, 0.0, 0.0], [0.8391493558883667, 0.1608506143093109, 0.0, 0.0], [0.7318846583366394, 0.12435775250196457, 0.1437576413154602, 0.0], [0.7835802435874939, 0.02795291692018509, 0.15891575813293457, 0.02955106645822525]], [[1.0, 0.0, 0.0, 0.0], [0.9620153307914734, 0.03798465058207512, 0.0, 0.0], [0.9300343990325928, 0.032783638685941696, 0.037181973457336426, 0.0], [0.9379732608795166, 0.027875877916812897, 0.02826903760433197, 0.00588188786059618]], [[1.0, 0.0, 0.0, 0.0], [0.9568069577217102, 0.043193068355321884, 0.0, 0.0], [0.9004090428352356, 0.04821838438510895, 0.05137252435088158, 0.0], [0.8455994725227356, 0.04955178499221802, 0.05498410388827324, 0.04986468330025673]], [[1.0, 0.0, 0.0, 0.0], [0.9763625264167786, 0.023637479171156883, 0.0, 0.0], [0.9349883794784546, 0.0352482870221138, 0.029763314872980118, 0.0], [0.9335187673568726, 0.039609454572200775, 0.021343547850847244, 0.005528231151401997]], [[1.0, 0.0, 0.0, 0.0], [0.9593993425369263, 0.040600668638944626, 0.0, 0.0], [0.9188076257705688, 0.03174203634262085, 0.04945032298564911, 0.0], [0.9076725244522095, 0.015262854285538197, 0.03661103919148445, 0.04045350104570389]], [[1.0, 0.0, 0.0, 0.0], [0.9688215255737305, 0.031178466975688934, 0.0, 0.0], [0.9666492342948914, 0.017512597143650055, 0.015838123857975006, 0.0], [0.8833913207054138, 0.051610320806503296, 0.05184532329440117, 0.013153048232197762]], [[1.0, 0.0, 0.0, 0.0], [0.9804984927177429, 0.01950152963399887, 0.0, 0.0], [0.953402042388916, 0.014717183075845242, 0.03188076987862587, 0.0], [0.9505434632301331, 0.02538631483912468, 0.020113958045840263, 0.00395620334893465]], [[1.0, 0.0, 0.0, 0.0], [0.9581118226051331, 0.04188825190067291, 0.0, 0.0], [0.7625529170036316, 0.09703418612480164, 0.14041292667388916, 0.0], [0.7618116140365601, 0.03211081773042679, 0.09744568914175034, 0.10863178968429565]], [[1.0, 0.0, 0.0, 0.0], [0.9889003038406372, 0.011099740862846375, 0.0, 0.0], [0.9859681129455566, 0.007783365435898304, 0.006248443387448788, 0.0], [0.964647114276886, 0.019865216687321663, 0.011471571400761604, 0.004016125109046698]]], [[[1.0, 0.0, 0.0, 0.0], [0.8864973783493042, 0.113502636551857, 0.0, 0.0], [0.8789259195327759, 0.0932716354727745, 0.027802418917417526, 0.0], [0.7940932512283325, 0.12063684314489365, 0.07414542883634567, 0.01112454105168581]], [[1.0, 0.0, 0.0, 0.0], [0.9543800354003906, 0.04562002420425415, 0.0, 0.0], [0.9232466220855713, 0.03939611837267876, 0.0373571552336216, 0.0], [0.9503932595252991, 0.023855185136198997, 0.01886543445289135, 0.006886076647788286]], [[1.0, 0.0, 0.0, 0.0], [0.9586296677589417, 0.041370317339897156, 0.0, 0.0], [0.8613924980163574, 0.07946491241455078, 0.0591425783932209, 0.0], [0.8320450782775879, 0.08810406178236008, 0.06639304757118225, 0.013457763008773327]], [[1.0, 0.0, 0.0, 0.0], [0.9581695795059204, 0.041830457746982574, 0.0, 0.0], [0.8633371591567993, 0.09287993609905243, 0.04378292337059975, 0.0], [0.9051235318183899, 0.04865259304642677, 0.022762445732951164, 0.023461459204554558]], [[1.0, 0.0, 0.0, 0.0], [0.971261739730835, 0.028738204389810562, 0.0, 0.0], [0.84889155626297, 0.061148639768362045, 0.0899597778916359, 0.0], [0.7304919362068176, 0.07432588189840317, 0.09967825561761856, 0.09550387412309647]], [[1.0, 0.0, 0.0, 0.0], [0.9071662425994873, 0.09283369779586792, 0.0, 0.0], [0.6931465268135071, 0.1139979362487793, 0.19285555183887482, 0.0], [0.8986860513687134, 0.022321369498968124, 0.0429045669734478, 0.03608804941177368]], [[1.0, 0.0, 0.0, 0.0], [0.9293556809425354, 0.07064434140920639, 0.0, 0.0], [0.8367434144020081, 0.10872092843055725, 0.054535701870918274, 0.0], [0.8608494997024536, 0.07123038917779922, 0.05457840487360954, 0.01334172673523426]], [[1.0, 0.0, 0.0, 0.0], [0.9322729706764221, 0.06772702187299728, 0.0, 0.0], [0.8862116932868958, 0.04236219823360443, 0.07142603397369385, 0.0], [0.804527223110199, 0.040870726108551025, 0.0903048887848854, 0.06429722160100937]], [[1.0, 0.0, 0.0, 0.0], [0.9781882762908936, 0.021811723709106445, 0.0, 0.0], [0.972743034362793, 0.013820390217006207, 0.013436590321362019, 0.0], [0.9758850932121277, 0.0052148327231407166, 0.005642260890454054, 0.013257873244583607]], [[1.0, 0.0, 0.0, 0.0], [0.7523583769798279, 0.24764156341552734, 0.0, 0.0], [0.5019503235816956, 0.1640997976064682, 0.33394989371299744, 0.0], [0.7590861320495605, 0.0437958687543869, 0.12566648423671722, 0.07145153731107712]], [[1.0, 0.0, 0.0, 0.0], [0.9554508328437805, 0.044549185782670975, 0.0, 0.0], [0.9342920780181885, 0.03649477660655975, 0.02921314164996147, 0.0], [0.9238194823265076, 0.03890111297369003, 0.03015044517815113, 0.007128950208425522]], [[1.0, 0.0, 0.0, 0.0], [0.9043543934822083, 0.09564556926488876, 0.0, 0.0], [0.9300746321678162, 0.043845705687999725, 0.026079723611474037, 0.0], [0.7731170654296875, 0.050871916115283966, 0.11076317727565765, 0.0652478039264679]]], [[[1.0, 0.0, 0.0, 0.0], [0.6846181154251099, 0.31538185477256775, 0.0, 0.0], [0.3272261619567871, 0.3136214017868042, 0.3591524362564087, 0.0], [0.28873831033706665, 0.20657342672348022, 0.20798607170581818, 0.29670223593711853]], [[1.0, 0.0, 0.0, 0.0], [0.9312141537666321, 0.0687859058380127, 0.0, 0.0], [0.8793478012084961, 0.06257884949445724, 0.058073315769433975, 0.0], [0.8864972591400146, 0.0425117202103138, 0.034507401287555695, 0.03648369759321213]], [[1.0, 0.0, 0.0, 0.0], [0.9740089178085327, 0.025991037487983704, 0.0, 0.0], [0.8993344902992249, 0.05028178170323372, 0.050383713096380234, 0.0], [0.9128904938697815, 0.027618031948804855, 0.04365304857492447, 0.015838420018553734]], [[1.0, 0.0, 0.0, 0.0], [0.8313109874725342, 0.16868899762630463, 0.0, 0.0], [0.8412584066390991, 0.08335168659687042, 0.07538992911577225, 0.0], [0.8332040309906006, 0.04624852538108826, 0.07621588557958603, 0.044331617653369904]], [[1.0, 0.0, 0.0, 0.0], [0.8731979131698608, 0.12680207192897797, 0.0, 0.0], [0.8157558441162109, 0.09303369373083115, 0.09121055901050568, 0.0], [0.7348884344100952, 0.06551358103752136, 0.06824001669883728, 0.13135792315006256]], [[1.0, 0.0, 0.0, 0.0], [0.9549729824066162, 0.045027025043964386, 0.0, 0.0], [0.9184066653251648, 0.04648442938923836, 0.03510890528559685, 0.0], [0.9598978757858276, 0.018655594438314438, 0.011372693814337254, 0.01007384154945612]], [[1.0, 0.0, 0.0, 0.0], [0.9425029754638672, 0.0574970543384552, 0.0, 0.0], [0.8904843926429749, 0.059747856110334396, 0.04976780712604523, 0.0], [0.9303671717643738, 0.03467365354299545, 0.026911389082670212, 0.008047860115766525]], [[1.0, 0.0, 0.0, 0.0], [0.8861631155014038, 0.1138368770480156, 0.0, 0.0], [0.7801804542541504, 0.09589225053787231, 0.12392730265855789, 0.0], [0.813708484172821, 0.0657411441206932, 0.061849839985370636, 0.05870051309466362]], [[1.0, 0.0, 0.0, 0.0], [5.394863910623826e-05, 0.9999459981918335, 0.0, 0.0], [1.0295632819179446e-05, 0.5862687826156616, 0.4137209951877594, 0.0], [0.00017180161376018077, 0.15909713506698608, 0.3270132541656494, 0.5137178301811218]], [[1.0, 0.0, 0.0, 0.0], [0.9380736351013184, 0.06192633509635925, 0.0, 0.0], [0.9011828303337097, 0.05448286607861519, 0.044334277510643005, 0.0], [0.9323163032531738, 0.03217263147234917, 0.017909713089466095, 0.01760145090520382]], [[1.0, 0.0, 0.0, 0.0], [0.7672830820083618, 0.232716903090477, 0.0, 0.0], [0.5923321843147278, 0.17692995071411133, 0.2307378500699997, 0.0], [0.7143336534500122, 0.06842997670173645, 0.1164291575551033, 0.10080726444721222]], [[1.0, 0.0, 0.0, 0.0], [0.9365187287330627, 0.06348133087158203, 0.0, 0.0], [0.8265508413314819, 0.09784789383411407, 0.07560129463672638, 0.0], [0.7361746430397034, 0.07360215485095978, 0.0997605249285698, 0.09046268463134766]]]], \"left_text\": [\"Machine\", \" Learning\", \" algorithms\", \" are\"], \"right_text\": [\"Machine\", \" Learning\", \" algorithms\", \" are\"]}], \"default_filter\": \"0\", \"root_div_id\": \"bertviz-6f380e475bd44dc99a57a16401bd9f53\", \"layer\": null, \"heads\": null, \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]} is a template marker that is replaced by actual params.\n",
              "    const TEXT_SIZE = 15;\n",
              "    const BOXWIDTH = 110;\n",
              "    const BOXHEIGHT = 22.5;\n",
              "    const MATRIX_WIDTH = 115;\n",
              "    const CHECKBOX_SIZE = 20;\n",
              "    const TEXT_TOP = 30;\n",
              "\n",
              "    console.log(\"d3 version\", d3.version)\n",
              "    let headColors;\n",
              "    try {\n",
              "        headColors = d3.scaleOrdinal(d3.schemeCategory10);\n",
              "    } catch (err) {\n",
              "        console.log('Older d3 version')\n",
              "        headColors = d3.scale.category10();\n",
              "    }\n",
              "    let config = {};\n",
              "    initialize();\n",
              "    renderVis();\n",
              "\n",
              "    function initialize() {\n",
              "        config.attention = params['attention'];\n",
              "        config.filter = params['default_filter'];\n",
              "        config.rootDivId = params['root_div_id'];\n",
              "        config.nLayers = config.attention[config.filter]['attn'].length;\n",
              "        config.nHeads = config.attention[config.filter]['attn'][0].length;\n",
              "        config.layers = params['include_layers']\n",
              "\n",
              "        if (params['heads']) {\n",
              "            config.headVis = new Array(config.nHeads).fill(false);\n",
              "            params['heads'].forEach(x => config.headVis[x] = true);\n",
              "        } else {\n",
              "            config.headVis = new Array(config.nHeads).fill(true);\n",
              "        }\n",
              "        config.initialTextLength = config.attention[config.filter].right_text.length;\n",
              "        config.layer_seq = (params['layer'] == null ? 0 : config.layers.findIndex(layer => params['layer'] === layer));\n",
              "        config.layer = config.layers[config.layer_seq]\n",
              "\n",
              "        let layerEl = $(`#${config.rootDivId} #layer`);\n",
              "        for (const layer of config.layers) {\n",
              "            layerEl.append($(\"<option />\").val(layer).text(layer));\n",
              "        }\n",
              "        layerEl.val(config.layer).change();\n",
              "        layerEl.on('change', function (e) {\n",
              "            config.layer = +e.currentTarget.value;\n",
              "            config.layer_seq = config.layers.findIndex(layer => config.layer === layer);\n",
              "            renderVis();\n",
              "        });\n",
              "\n",
              "        $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "            config.filter = e.currentTarget.value;\n",
              "            renderVis();\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderVis() {\n",
              "\n",
              "        // Load parameters\n",
              "        const attnData = config.attention[config.filter];\n",
              "        const leftText = attnData.left_text;\n",
              "        const rightText = attnData.right_text;\n",
              "\n",
              "        // Select attention for given layer\n",
              "        const layerAttention = attnData.attn[config.layer_seq];\n",
              "\n",
              "        // Clear vis\n",
              "        $(`#${config.rootDivId} #vis`).empty();\n",
              "\n",
              "        // Determine size of visualization\n",
              "        const height = Math.max(leftText.length, rightText.length) * BOXHEIGHT + TEXT_TOP;\n",
              "        const svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "            .append('svg')\n",
              "            .attr(\"width\", \"100%\")\n",
              "            .attr(\"height\", height + \"px\");\n",
              "\n",
              "        // Display tokens on left and right side of visualization\n",
              "        renderText(svg, leftText, true, layerAttention, 0);\n",
              "        renderText(svg, rightText, false, layerAttention, MATRIX_WIDTH + BOXWIDTH);\n",
              "\n",
              "        // Render attention arcs\n",
              "        renderAttention(svg, layerAttention);\n",
              "\n",
              "        // Draw squares at top of visualization, one for each head\n",
              "        drawCheckboxes(0, svg, layerAttention);\n",
              "    }\n",
              "\n",
              "    function renderText(svg, text, isLeft, attention, leftPos) {\n",
              "\n",
              "        const textContainer = svg.append(\"svg:g\")\n",
              "            .attr(\"id\", isLeft ? \"left\" : \"right\");\n",
              "\n",
              "        // Add attention highlights superimposed over words\n",
              "        textContainer.append(\"g\")\n",
              "            .classed(\"attentionBoxes\", true)\n",
              "            .selectAll(\"g\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\"rect\")\n",
              "            .data(d => isLeft ? d : transpose(d)) // if right text, transpose attention to get right-to-left weights\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"x\", function () {\n",
              "                var headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                return leftPos + boxOffsets(headIndex);\n",
              "            })\n",
              "            .attr(\"y\", (+1) * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "            .attr(\"height\", BOXHEIGHT)\n",
              "            .attr(\"fill\", function () {\n",
              "                return headColors(+this.parentNode.getAttribute(\"head-index\"))\n",
              "            })\n",
              "            .style(\"opacity\", 0.0);\n",
              "\n",
              "        const tokenContainer = textContainer.append(\"g\").selectAll(\"g\")\n",
              "            .data(text)\n",
              "            .enter()\n",
              "            .append(\"g\");\n",
              "\n",
              "        // Add gray background that appears when hovering over text\n",
              "        tokenContainer.append(\"rect\")\n",
              "            .classed(\"background\", true)\n",
              "            .style(\"opacity\", 0.0)\n",
              "            .attr(\"fill\", \"lightgray\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "            .attr(\"width\", BOXWIDTH)\n",
              "            .attr(\"height\", BOXHEIGHT);\n",
              "\n",
              "        // Add token text\n",
              "        const textEl = tokenContainer.append(\"text\")\n",
              "            .text(d => d)\n",
              "            .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "            .style(\"cursor\", \"default\")\n",
              "            .style(\"-webkit-user-select\", \"none\")\n",
              "            .attr(\"x\", leftPos)\n",
              "            .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT);\n",
              "\n",
              "        if (isLeft) {\n",
              "            textEl.style(\"text-anchor\", \"end\")\n",
              "                .attr(\"dx\", BOXWIDTH - 0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        } else {\n",
              "            textEl.style(\"text-anchor\", \"start\")\n",
              "                .attr(\"dx\", +0.5 * TEXT_SIZE)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "\n",
              "            // Show gray background for moused-over token\n",
              "            textContainer.selectAll(\".background\")\n",
              "                .style(\"opacity\", (d, i) => i === index ? 1.0 : 0.0)\n",
              "\n",
              "            // Reset visibility attribute for any previously highlighted attention arcs\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null)\n",
              "\n",
              "            // Hide group containing attention arcs\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"hidden\");\n",
              "\n",
              "            // Set to visible appropriate attention arcs to be highlighted\n",
              "            if (isLeft) {\n",
              "                svg.select(\"#attention\").selectAll(\"line[left-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            } else {\n",
              "                svg.select(\"#attention\").selectAll(\"line[right-token-index='\" + index + \"']\").attr(\"visibility\", \"visible\");\n",
              "            }\n",
              "\n",
              "            // Update color boxes superimposed over tokens\n",
              "            const id = isLeft ? \"right\" : \"left\";\n",
              "            const leftPos = isLeft ? MATRIX_WIDTH + BOXWIDTH : 0;\n",
              "            svg.select(\"#\" + id)\n",
              "                .selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .attr(\"head-index\", (d, i) => i)\n",
              "                .selectAll(\"rect\")\n",
              "                .attr(\"x\", function () {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    return leftPos + boxOffsets(headIndex);\n",
              "                })\n",
              "                .attr(\"y\", (d, i) => TEXT_TOP + i * BOXHEIGHT)\n",
              "                .attr(\"width\", BOXWIDTH / activeHeads())\n",
              "                .attr(\"height\", BOXHEIGHT)\n",
              "                .style(\"opacity\", function (d) {\n",
              "                    const headIndex = +this.parentNode.getAttribute(\"head-index\");\n",
              "                    if (config.headVis[headIndex])\n",
              "                        if (d) {\n",
              "                            return d[index];\n",
              "                        } else {\n",
              "                            return 0.0;\n",
              "                        }\n",
              "                    else\n",
              "                        return 0.0;\n",
              "                });\n",
              "        });\n",
              "\n",
              "        textContainer.on(\"mouseleave\", function () {\n",
              "\n",
              "            // Unhighlight selected token\n",
              "            d3.select(this).selectAll(\".background\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "\n",
              "            // Reset visibility attributes for previously selected lines\n",
              "            svg.select(\"#attention\")\n",
              "                .selectAll(\"line[visibility='visible']\")\n",
              "                .attr(\"visibility\", null) ;\n",
              "            svg.select(\"#attention\").attr(\"visibility\", \"visible\");\n",
              "\n",
              "            // Reset highlights superimposed over tokens\n",
              "            svg.selectAll(\".attentionBoxes\")\n",
              "                .selectAll(\"g\")\n",
              "                .selectAll(\"rect\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function renderAttention(svg, attention) {\n",
              "\n",
              "        // Remove previous dom elements\n",
              "        svg.select(\"#attention\").remove();\n",
              "\n",
              "        // Add new elements\n",
              "        svg.append(\"g\")\n",
              "            .attr(\"id\", \"attention\") // Container for all attention arcs\n",
              "            .selectAll(\".headAttention\")\n",
              "            .data(attention)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"headAttention\", true) // Group attention arcs by head\n",
              "            .attr(\"head-index\", (d, i) => i)\n",
              "            .selectAll(\".tokenAttention\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"g\")\n",
              "            .classed(\"tokenAttention\", true) // Group attention arcs by left token\n",
              "            .attr(\"left-token-index\", (d, i) => i)\n",
              "            .selectAll(\"line\")\n",
              "            .data(d => d)\n",
              "            .enter()\n",
              "            .append(\"line\")\n",
              "            .attr(\"x1\", BOXWIDTH)\n",
              "            .attr(\"y1\", function () {\n",
              "                const leftTokenIndex = +this.parentNode.getAttribute(\"left-token-index\")\n",
              "                return TEXT_TOP + leftTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2)\n",
              "            })\n",
              "            .attr(\"x2\", BOXWIDTH + MATRIX_WIDTH)\n",
              "            .attr(\"y2\", (d, rightTokenIndex) => TEXT_TOP + rightTokenIndex * BOXHEIGHT + (BOXHEIGHT / 2))\n",
              "            .attr(\"stroke-width\", 2)\n",
              "            .attr(\"stroke\", function () {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                return headColors(headIndex)\n",
              "            })\n",
              "            .attr(\"left-token-index\", function () {\n",
              "                return +this.parentNode.getAttribute(\"left-token-index\")\n",
              "            })\n",
              "            .attr(\"right-token-index\", (d, i) => i)\n",
              "        ;\n",
              "        updateAttention(svg)\n",
              "    }\n",
              "\n",
              "    function updateAttention(svg) {\n",
              "        svg.select(\"#attention\")\n",
              "            .selectAll(\"line\")\n",
              "            .attr(\"stroke-opacity\", function (d) {\n",
              "                const headIndex = +this.parentNode.parentNode.getAttribute(\"head-index\");\n",
              "                // If head is selected\n",
              "                if (config.headVis[headIndex]) {\n",
              "                    // Set opacity to attention weight divided by number of active heads\n",
              "                    return d / activeHeads()\n",
              "                } else {\n",
              "                    return 0.0;\n",
              "                }\n",
              "            })\n",
              "    }\n",
              "\n",
              "    function boxOffsets(i) {\n",
              "        const numHeadsAbove = config.headVis.reduce(\n",
              "            function (acc, val, cur) {\n",
              "                return val && cur < i ? acc + 1 : acc;\n",
              "            }, 0);\n",
              "        return numHeadsAbove * (BOXWIDTH / activeHeads());\n",
              "    }\n",
              "\n",
              "    function activeHeads() {\n",
              "        return config.headVis.reduce(function (acc, val) {\n",
              "            return val ? acc + 1 : acc;\n",
              "        }, 0);\n",
              "    }\n",
              "\n",
              "    function drawCheckboxes(top, svg) {\n",
              "        const checkboxContainer = svg.append(\"g\");\n",
              "        const checkbox = checkboxContainer.selectAll(\"rect\")\n",
              "            .data(config.headVis)\n",
              "            .enter()\n",
              "            .append(\"rect\")\n",
              "            .attr(\"fill\", (d, i) => headColors(i))\n",
              "            .attr(\"x\", (d, i) => i * CHECKBOX_SIZE)\n",
              "            .attr(\"y\", top)\n",
              "            .attr(\"width\", CHECKBOX_SIZE)\n",
              "            .attr(\"height\", CHECKBOX_SIZE);\n",
              "\n",
              "        function updateCheckboxes() {\n",
              "            checkboxContainer.selectAll(\"rect\")\n",
              "                .data(config.headVis)\n",
              "                .attr(\"fill\", (d, i) => d ? headColors(i): lighten(headColors(i)));\n",
              "        }\n",
              "\n",
              "        updateCheckboxes();\n",
              "\n",
              "        checkbox.on(\"click\", function (d, i) {\n",
              "            if (config.headVis[i] && activeHeads() === 1) return;\n",
              "            config.headVis[i] = !config.headVis[i];\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "\n",
              "        checkbox.on(\"dblclick\", function (d, i) {\n",
              "            // If we double click on the only active head then reset\n",
              "            if (config.headVis[i] && activeHeads() === 1) {\n",
              "                config.headVis = new Array(config.nHeads).fill(true);\n",
              "            } else {\n",
              "                config.headVis = new Array(config.nHeads).fill(false);\n",
              "                config.headVis[i] = true;\n",
              "            }\n",
              "            updateCheckboxes();\n",
              "            updateAttention(svg);\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function lighten(color) {\n",
              "        const c = d3.hsl(color);\n",
              "        const increment = (1 - c.l) * 0.6;\n",
              "        c.l += increment;\n",
              "        c.s -= increment;\n",
              "        return c;\n",
              "    }\n",
              "\n",
              "    function transpose(mat) {\n",
              "        return mat[0].map(function (col, i) {\n",
              "            return mat.map(function (row) {\n",
              "                return row[i];\n",
              "            });\n",
              "        });\n",
              "    }\n",
              "\n",
              "});"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating text with decoder-only models\n",
        "\n",
        "To generate new text, we are interested in the predicted value for the last token.\n",
        "\n",
        "We need to convert the output logits to probabilities, and then take the max value, which will correspond to the ID of the next predicted token. Finally, we can convert the ID to its corresponding token."
      ],
      "metadata": {
        "id": "OuTWjXHzIX2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = output[\"logits\"][:, -1, :]\n",
        "probabilities = torch.softmax(logits, dim=1)\n",
        "pred_token_id = torch.argmax(probabilities, dim=1, keepdim=True).item()\n",
        "pred_token = tokenizer.decode(pred_token_id)\n",
        "print(pred_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3FtJk2pIZTv",
        "outputId": "18693eed-7aee-487a-859f-64875025c839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can generate longer sentences by repeating this process, feeding at each step the sequence generated in the previous steps."
      ],
      "metadata": {
        "id": "EDytcHXuIajY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_tokens_ids = []\n",
        "input_ids = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"]\n",
        "for i in range(50):\n",
        "    output = model(input_ids=input_ids)\n",
        "    logits = output[\"logits\"][:, -1, :]\n",
        "    probabilities = torch.softmax(logits, dim=1)\n",
        "    pred_token_id = torch.argmax(probabilities, dim=1, keepdim=True)\n",
        "    generated_tokens_ids.append(pred_token_id.item())\n",
        "    input_ids = torch.cat((input_ids, pred_token_id), dim=1)\n",
        "generated_text = tokenizer.decode(generated_tokens_ids)\n",
        "print(sentence, \"...\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoaH-zsHIaod",
        "outputId": "1013ad50-6f60-40ca-fb92-5bd7942f0d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Machine Learning algorithms are ...\n",
            " used to train neural networks to perform tasks such as predicting the future.\n",
            "\n",
            "The researchers used a combination of machine learning and machine learning algorithms to create a new type of machine learning algorithm called a \"supervised learning algorithm.\"\n",
            "\n",
            "The researchers used\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The procedure above is deterministic. To add some variety in the produced outputs, typically a random sampling is performed on the top-k predicted tokens, based on their probability.\n",
        "\n",
        "Hugging Face also provides `pipeline` objects that integrate all the required operations for the most common tasks, like text generation."
      ],
      "metadata": {
        "id": "EN5C62q5IctD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "\n",
        "# set_seed(42)\n",
        "model = pipeline(\"text-generation\", model=\"gpt2\", max_length=5)\n",
        "generated_text = model(sentence)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z125LfsCIc1e",
        "outputId": "8ad17f87-f3cf-4018-ab51-f158dd9d5640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'Machine Learning algorithms are often described as \"smart\" machines, so they require a lot of control over the machine learning algorithms.\\n\\nWhy is there a problem with this?\\n\\nWhen you look at the performance of a smart machine, one of'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning a encoder-only model\n",
        "\n",
        "We will now load a pre-trained encoder-only model, that maps the input text into a hidden space, capturing high-level relationships and concepts. On top of this representation, we can attach task-specific layers (e.g., a linear classifier) and fine-tune the whole model on the given task. Usually, just a few epochs with a small learning rate are enough.\n",
        "\n",
        "We will use DistilBERT [4], a distilled (i.e., with reduced size but similar performance) version of BERT (Bidirectional Encoder Representations from Transformers) [5], and fine-tune it for the sentiment classification task.\n",
        "\n",
        "### Dataset loading\n",
        "\n",
        "We first load the popular `emotion` dataset, which consists of Twitter messages labeled with six basic emotions: anger, fear, joy, love, sadness, and surprise."
      ],
      "metadata": {
        "id": "9FNNgXgM7xEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"dair-ai/emotion\", \"split\")"
      ],
      "metadata": {
        "id": "9UbUMzOdcIeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ds)\n",
        "print(ds[\"train\"][:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DTL3apPcLWP",
        "outputId": "1c55d248-8635-4064-c145-daf47e6ec3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 16000\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 2000\n",
            "    })\n",
            "})\n",
            "{'text': ['i didnt feel humiliated', 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'im grabbing a minute to post i feel greedy wrong'], 'label': [0, 0, 3]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model loading\n",
        "\n",
        "We now load the pre-trained tokenizer and model from Hugging Face. Note that we are wrapping the model into a class that automatically attaches a (randomly initialized) classification layer on top of the encoder's last hidden layer. For this reason, the warning we get is expected.\n",
        "\n",
        "We also have to set the number of output classes we need, which is $6$."
      ],
      "metadata": {
        "id": "5EHs8WvScOL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert/distilbert-base-uncased\", num_labels=6)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y47VmumTeGq",
        "outputId": "ee7d077b-8bd4-45aa-cea7-f21f34d4e58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DistilBertForSequenceClassification(\n",
            "  (distilbert): DistilBertModel(\n",
            "    (embeddings): Embeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (layer): ModuleList(\n",
            "        (0-5): 6 x TransformerBlock(\n",
            "          (attention): DistilBertSdpaAttention(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "          )\n",
            "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (ffn): FFN(\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (activation): GELUActivation()\n",
            "          )\n",
            "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
            "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also note that the classification layer has an input size equal to a single-token embedding size (i.e., $768$). Indeed, the classifier only takes as input the hidden representation of the first input token (which is the special sequence start `[CLS]` token).\n",
        "\n",
        "### Tokenization\n",
        "\n",
        "We then define a tokenization function and apply it to the entire dataset.\n",
        "\n",
        "As BERT expects fixed-length inputs of 512 tokens, we need to set some parameters in the tokenizer. If the input sequence is longer, it is truncated; if shorter, padding tokens are added until the requested size is reached. Note that special `[CLS]` and `[SEP]` tokens are always added at start and end positions, respectively."
      ],
      "metadata": {
        "id": "rn64OupSTDSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
        "\n",
        "\n",
        "tokenized_datasets = ds.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "KU4yae45YRTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenized_datasets[\"train\"][0])\n",
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06tTE55UZcpQ",
        "outputId": "2d091076-2012-4e6b-d9f5-ee047a3f027b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'i didnt feel humiliated', 'label': 0, 'input_ids': [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'unk_token': '[UNK]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We set now the training parameters using the class provided by the transformers library."
      ],
      "metadata": {
        "id": "N7tpfOkrfBDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=1\n",
        ")"
      ],
      "metadata": {
        "id": "gYX6urIieHXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also define a metric to be used during the validation phase in the training process, i.e., the accuracy."
      ],
      "metadata": {
        "id": "cma3zv2cpjBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = np.mean(predictions == labels)\n",
        "    return {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "Y05tupAafKoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we instantiate a trainer, provided by the transformer library, which will automatically handle the training loop. We also subsample the dataset to speed up the training."
      ],
      "metadata": {
        "id": "etYylRstpxag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42).select(range(5000)),\n",
        "    eval_dataset=tokenized_datasets[\"validation\"].shuffle(seed=42).select(range(1000)),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "eBklhuVefUIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can launch the model fine-tuning!"
      ],
      "metadata": {
        "id": "6Q2tuxIFp_M0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "a72W_EjmfWvr",
        "outputId": "c59d1154-2e8b-4371-aa35-28516fb2922d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='237' max='237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [237/237 03:10, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.555800</td>\n",
              "      <td>0.537940</td>\n",
              "      <td>0.837000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.299300</td>\n",
              "      <td>0.265765</td>\n",
              "      <td>0.923000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.372800</td>\n",
              "      <td>0.232629</td>\n",
              "      <td>0.918000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=237, training_loss=0.5643707242193101, metrics={'train_runtime': 192.765, 'train_samples_per_second': 77.815, 'train_steps_per_second': 1.229, 'total_flos': 1987152721920000.0, 'train_loss': 0.5643707242193101, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "[1] Vaswani, A., Shazeer, N.M., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, L., & Polosukhin, I. (2017). Attention is All you Need. Neural Information Processing Systems.\n",
        "\n",
        "[2] Raschka, S. (2024). Build A Large Language Model (From Scratch). Manning. ISBN: 978-1633437166.\n",
        "\n",
        "[3] Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., & Sutskever, I. (2019). Language Models are Unsupervised Multitask Learners.\n",
        "\n",
        "[4] Sanh, V., Debut, L., Chaumond, J., & Wolf, T. (2019). DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. ArXiv, abs/1910.01108.\n",
        "\n",
        "[5] Devlin, J., Chang, M., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. North American Chapter of the Association for Computational Linguistics."
      ],
      "metadata": {
        "id": "aYx6_Qx98JZ-"
      }
    }
  ]
}